{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff344490-394e-479f-bc97-17882476d056",
   "metadata": {},
   "source": [
    "## STEP 0 - install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3366dc0c-7a3d-4955-9b84-b4d06301c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to enter OpenAI key here and then we can run all cells freely...\n",
    "import os\n",
    "from getpass import getpass\n",
    "from openai import OpenAI\n",
    "\n",
    "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
    "    openai_api_key = getpass(\"üîë Enter your OpenAI API key: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9206afd3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# source is https://www.youtube.com/watch?v=GH3lrOsU3AU\n",
    "# and notebook is https://github.com/DataTalksClub/llm-zoomcamp/blob/main/0a-agents/notebook.ipynb\n",
    "# Follow along this tutorial: https://github.com/alexeygrigorev/rag-agents-workshop\n",
    "\n",
    "# STEP 0 - installing packages we need here and in the VS code terminal:\n",
    "\n",
    "# Run in VS code terminal:\n",
    "# pip install --upgrade pip # no reminders after!\n",
    "# pip install tqdm notebook==7.1.2 openai elasticsearch==8.13.0 pandas scikit-learn ipywidgets\n",
    "# jupyter notebook # to run jupyter engine locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4e37acb-1feb-4da5-9ab5-b35d80df1171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install minsearch -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e675499-6969-48f7-b42a-3b51a37c3516",
   "metadata": {},
   "source": [
    "## STEP 1 - download evaluation data from Github and build in-memory search index with minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d23e682f-5025-448e-9687-28e26d0fce22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Problem description\\nInfrastructure created in AWS with CD-Deploy Action needs to be destroyed\\nSolution description\\nFrom local:\\nterraform init -backend-config=\"key=mlops-zoomcamp-prod.tfstate\" --reconfigure\\nterraform destroy --var-file vars/prod.tfvars\\nAdded by Erick Calderin',\n",
       " 'section': 'Module 6: Best practices',\n",
       " 'question': 'How to destroy infrastructure created via GitHub Actions',\n",
       " 'course': 'mlops-zoomcamp'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download our FAQ dataset\n",
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "documents[-1] # to see a format of downloaded FAQ dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d7c1561-c33b-4817-9160-0d659cd8102e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x7473af0c0cb0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build index - takes a few seconds with minsearch\n",
    "\n",
    "from minsearch import AppendableIndex\n",
    "\n",
    "index = AppendableIndex(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d58d90-b092-4318-9daf-5c22ed75bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a search function with weights: boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "# number of results 5 and course is hard coded here  - filter_dict={'course': 'data-engineering-zoomcamp'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee44aa1e-eb04-436a-bd70-c944c625b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Can I still join the course?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "526dec30-411e-4965-8c95-8fa2f136cb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I still join the course after the start date?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 2},\n",
       " {'text': \"No, you can only get a certificate if you finish the course with a ‚Äúlive‚Äù cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Certificate - Can I follow the course in a self-paced mode and get a certificate?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 11},\n",
       " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 7},\n",
       " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  ‚ÄúOffice Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon‚Äôt forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 0},\n",
       " {'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 3}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if our search function works \n",
    "\n",
    "search(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53aa958-7f3d-4366-a8d8-77f5eeb644e1",
   "metadata": {},
   "source": [
    "## STEP 2 - build prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10a7ef93-818e-4e91-9f57-52b34c7c6e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a prompt\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2c19daf-7c13-4a5e-a202-e92fe9871560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
      "Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "\n",
      "<QUESTION>\n",
      "Can I still join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT>\n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a ‚Äúlive‚Äù cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  ‚ÄúOffice Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don‚Äôt forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?\n",
      "answer: You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\n",
      "\n",
      "\n",
      "</CONTEXT>\n"
     ]
    }
   ],
   "source": [
    "# test how our prompt build works by calling search(question)\n",
    "\n",
    "prompt = build_prompt(question, search(question))\n",
    "print(prompt) # better formatted for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1437dbe4-a21b-4d5b-b38c-fcb1c2a65faa",
   "metadata": {},
   "source": [
    "## STEP 3 - Connect to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "310bba81-83a1-45e9-a3c7-49be5bd834b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to LLM, we entered our API KEY already at the first cell\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8959bb41-fe64-4a0c-a513-09193cc1ff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = search(question)\n",
    "# just repeating step 1 - keyword search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f68040dd-3e23-4a44-8d55-30f651bce87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = build_prompt(question, search_results)\n",
    "# repeating step 2 - building prompt on top of search results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92bf5fd8-fa18-4c07-b8c3-96eaaada704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to send our prompt to llm \n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56cbbc89-489a-439f-886e-8c83fc3e1838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you can still join the course even after the start date. You are eligible to submit homework regardless of registration. However, keep in mind that there will be deadlines for the final projects, so it's important not to leave everything until the last minute.\n"
     ]
    }
   ],
   "source": [
    "# test if our llm can answer something meaningful based on prompt provided\n",
    "\n",
    "answer = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ada0a00b-186c-4ada-b4a8-a1b1732e81e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
      "Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "\n",
      "<QUESTION>\n",
      "Can I still join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT>\n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a ‚Äúlive‚Äù cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  ‚ÄúOffice Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don‚Äôt forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?\n",
      "answer: You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\n",
      "\n",
      "\n",
      "</CONTEXT>\n"
     ]
    }
   ],
   "source": [
    "print(prompt) # this is what we have sent to llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870cb933-452c-41f3-b99c-44c72bc0af59",
   "metadata": {},
   "source": [
    "## STEP 4 - assemble our RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71781bd1-7beb-4ad4-8ab8-5c15ddd7e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is our RAG pipeline\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "003417eb-7010-48af-bdbc-02da09f89fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but there is no information available in the provided context regarding how to patch KDE under FreeBSD. Please check the documentation or seek help from the FreeBSD community for guidance on this topic.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test by irrelevant question - something which is NOT in FAQ\n",
    "\n",
    "rag(\"How do I patch KDE under FreeBSD?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1788745b-4d66-4458-9e01-238b33536efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The context provided does not include any information regarding Shakespeare or his views on peeling a carrot. Therefore, I cannot provide an answer to that question based on the given information.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"What Shakespeare said about peeling a carrot?\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "321524b2-58ec-49a0-a6e5-0984cc69dcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To run Kafka in Docker, first ensure that your Kafka broker Docker container is working. You can check this by running the command `docker ps` to confirm the status of your containers. If the Kafka container is not running, navigate to the directory containing your docker-compose YAML file and execute the command `docker compose up -d` to start all the instances.\n"
     ]
    }
   ],
   "source": [
    "# relevant question - it actually was in FAQ\n",
    "answer = rag(\"How to run Kafka in Docker\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37a06640-c69c-4799-b4e6-8ce236fae194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patching KDE (or any software) under FreeBSD involves a few steps. Below is a general guide on how to apply a patch to the KDE desktop environment or its applications in FreeBSD. Keep in mind that this process might vary slightly depending on the specific package or port you are working with.\n",
      "\n",
      "### Prerequisites\n",
      "\n",
      "1. **Install FreeBSD Ports System**: Ensure that the Ports Collection is installed and up to date. You can update your ports tree using:\n",
      "   ```shell\n",
      "   portsnap fetch update\n",
      "   ```\n",
      "\n",
      "2. **Install Required Tools**: You might need utilities such as `patch` and a text editor like `vi` or `nano` to edit files. Install them if you haven‚Äôt already:\n",
      "   ```shell\n",
      "   pkg install patch vim\n",
      "   ```\n",
      "\n",
      "### Steps to Patch KDE under FreeBSD\n",
      "\n",
      "1. **Identify the Port**: Determine the KDE port you want to patch. KDE ports are typically located in `/usr/ports/x11/kde` or similar directories.\n",
      "\n",
      "2. **Download the Patch**: Obtain the patch file you want to apply. This may be provided by the developers or found online.\n",
      "\n",
      "3. **Navigate to the Port Directory**:\n",
      "   ```shell\n",
      "   cd /usr/ports/x11/kde/<specific-port>\n",
      "   ```\n",
      "\n",
      "4. **Apply the Patch**:\n",
      "   - Create a `files` directory inside the port directory if it does not exist:\n",
      "     ```shell\n",
      "     mkdir -p files\n",
      "     ```\n",
      "   - Move the patch file into the `files` directory:\n",
      "     ```shell\n",
      "     mv /path/to/your/patch/file.patch files/\n",
      "     ```\n",
      "   - Apply the patch using the `patch` command:\n",
      "     ```shell\n",
      "     patch < files/file.patch\n",
      "     ```\n",
      "\n",
      "   If the patch is already added in the `files/` directory of the port, you can run:\n",
      "   ```shell\n",
      "   make patch\n",
      "   ```\n",
      "\n",
      "5. **Recompile the Port**: After applying the patch, you will need to rebuild the port to apply the changes. Run:\n",
      "   ```shell\n",
      "   make clean install\n",
      "   ```\n",
      "\n",
      "6. **Test the Application**: Once the port has been recompiled, launch the KDE application or desktop environment to ensure your patch works as intended.\n",
      "\n",
      "7. **Maintain Your Changes**: Keep in mind that updating your ports collection may overwrite your changes. You may need to reapply patches after updates or consider maintaining your own fork of the port if extensive modifications are made.\n",
      "\n",
      "### Tips\n",
      "\n",
      "- Always back up existing files before applying patches, especially if you are modifying core KDE components.\n",
      "- Read the documentation accompanying the patch for any specific instructions or dependencies.\n",
      "- Check the FreeBSD forums or mailing lists for advice and context about any patches you are applying.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Apps and desktop environments like KDE can be patched under FreeBSD by modifying the ports system. Following the outlined steps allows you to keep your desktop environment up to date with custom changes or fixes. Remember to test thoroughly, especially if the patches address critical functionality.\n"
     ]
    }
   ],
   "source": [
    "# LLM by itself know the answer, but our RAG is prohibiting it\n",
    "# above rag(\"How do I patch KDE under FreeBSD?\") returned nothing, but - \n",
    "print(llm(\"How do I patch KDE under FreeBSD?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9eb3baa8-7046-4262-a63e-4b304fe0ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually this was the main idea for STEP 5 below - if llm can answer question by itself, nice!\n",
    "# if not - it should be able to search our FAQ database and build the context for answer..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f64f5c-3f07-4f42-aac4-ef1aa7b2a98b",
   "metadata": {},
   "source": [
    "## STEP 5 - \"Agentic\" RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "869f1f09-7145-49ee-a222-d173457b20ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# essentially we only modify our prompt - so llm can decide either to give an answer immediately\n",
    "# or use a SEARCH tool to get more CONTEXT from our FAQ\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "At the beginning the context is EMPTY.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "If CONTEXT is EMPTY, you can use our FAQ database.\n",
    "In this case, use the following output template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\"\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75385600-f09c-444a-8189-00d450e3321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Can I still join the course?'\n",
    "context = 'EMPTY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9642963-cdde-472e-b98b-1a134cc4b98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "Can I still join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "EMPTY\n",
      "</CONTEXT>\n",
      "\n",
      "If CONTEXT is EMPTY, you can use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(question=question, context=context)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d2c6d4e-5dfb-473c-a0c5-a655849e90db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n\"action\": \"SEARCH\",\\n\"reasoning\": \"The context is empty, so I will look for information in the FAQ database regarding course enrollment policies.\"\\n}'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_json = llm(prompt)\n",
    "answer_json \n",
    "# model decided to use \"SEARCH\" function because CONTEXT is empty\n",
    "# and provided a reason for it  - \"reasoning\": \"I am unsure about the specific enrollment dates..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b60d4dfe-ad36-4e86-a873-43c123206642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SEARCH'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# we can parse the llm answer and use tool if appropriate:\n",
    "\n",
    "answer = json.loads(answer_json)\n",
    "answer['action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d71f231-1936-48ec-a271-e77a83823e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets ask LLM something it knows already well:\n",
    "question = 'Can I run Docker on Windows 10?'\n",
    "context = 'EMPTY'\n",
    "prompt = prompt_template.format(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f1e9aa1-c624-4c31-b23a-4796fe243aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n\"action\": \"ANSWER\",\\n\"answer\": \"Yes, you can run Docker on Windows 10. Docker provides a Desktop application that allows you to run Docker containers and manage images on Windows 10. Make sure you have Windows 10 Pro, Enterprise, or Education edition for the best experience, as these versions support Hyper-V, which Docker Desktop relies on. If you\\'re using Windows 10 Home, you can still run Docker using the WSL 2 backend, which requires enabling the Windows Subsystem for Linux (WSL).\",\\n\"source\": \"OWN_KNOWLEDGE\"\\n}'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_json = llm(prompt)\n",
    "answer_json \n",
    "# it provides answer immediately - zero shot - action\": \"ANSWER\":\n",
    "# and says it knows it already - \"source\": \"OWN_KNOWLEDGE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c445f22-9ca0-4d4d-b5dc-84dfcaaaff42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ANSWER'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = json.loads(answer_json)\n",
    "answer['action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b107c7e-5b1d-4862-821b-edc3cb9be37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if model says SEARCH then we need to use a search tool and build context + update prompt\n",
    "\n",
    "def build_context(search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    return context.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b6c1333-832a-4378-b322-84c24611982b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "Can I still join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a ‚Äúlive‚Äù cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  ‚ÄúOffice Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don‚Äôt forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?\n",
      "answer: You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\n",
      "</CONTEXT>\n",
      "\n",
      "If CONTEXT is EMPTY, you can use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# asking something it should search for:\n",
    "question = 'Can I still join the course?'\n",
    "\n",
    "search_results = search(question)\n",
    "context = build_context(search_results)\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "print(prompt) # for better formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6e63838-4743-4629-b5ff-5e20e4b137ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"Yes, you can still join the course even after the start date. You are eligible to submit homework assignments, but make sure to pay attention to the deadlines for the final projects to avoid last-minute rushes.\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# lets ask llm after we performed the search as advised and updated llm context\n",
    "\n",
    "answer_json = llm(prompt)\n",
    "print(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "653e62b3-403f-4766-a302-32b224cd7c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to put everything together and parse our response json automatically\n",
    "# algo - if \"action\": \"SEARCH\" then llm uses our FAQ search tool\n",
    "# if \"action\": \"ANSWER\" - then it answers immediately ...\n",
    "\n",
    "def agentic_rag_v1(question):\n",
    "    context = \"EMPTY\"\n",
    "    prompt = prompt_template.format(question=question, context=context)\n",
    "    answer_json = llm(prompt)\n",
    "    answer = json.loads(answer_json)\n",
    "    print(answer)\n",
    "\n",
    "    if answer['action'] == 'SEARCH':\n",
    "        print('need to perform search...')\n",
    "        search_results = search(question)\n",
    "        context = build_context(search_results)\n",
    "        \n",
    "        prompt = prompt_template.format(question=question, context=context)\n",
    "        answer_json = llm(prompt)\n",
    "        answer = json.loads(answer_json)\n",
    "        print(answer)\n",
    "\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b8617e7-653c-4f9c-a952-0e4321bfb2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'SEARCH', 'reasoning': \"The student is asking about how to join the course, and I don't have information in the provided context.\"}\n",
      "need to perform search...\n",
      "{'action': 'SEARCH', 'reasoning': 'The context does not provide specific information on how to join the course, so I need to look in the FAQ database for relevant details.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': 'SEARCH',\n",
       " 'reasoning': 'The context does not provide specific information on how to join the course, so I need to look in the FAQ database for relevant details.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test our agentic RAG function\n",
    "\n",
    "agentic_rag_v1('how do I join the course?')\n",
    "# 'action': 'SEARCH', 'reasoning': 'The context is empty...\n",
    "\n",
    "# 'action': 'ANSWER'\n",
    "# 'source': 'OWN_KNOWLEDGE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b01c8ed2-2b6e-416d-93b7-511a3b2e8d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'ANSWER', 'answer': \"To patch KDE under FreeBSD, you typically need to follow these steps: 1. Install the required patches or source files; you may find these in the FreeBSD ports collection or the KDE repositories. 2. Navigate to the directory containing the KDE port (e.g., `/usr/ports/x11/kde5`). 3. Apply the patch using the `patch` command, specifying the patch file. For example: `patch < /path/to/your/patch.diff`. 4. If you're building from source, run `make` to rebuild the KDE package with the applied changes. 5. Finally, install the patched version using `make install clean`. Always ensure you have backups and test the patched version before deploying it into a production environment.\", 'source': 'OWN_KNOWLEDGE'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': \"To patch KDE under FreeBSD, you typically need to follow these steps: 1. Install the required patches or source files; you may find these in the FreeBSD ports collection or the KDE repositories. 2. Navigate to the directory containing the KDE port (e.g., `/usr/ports/x11/kde5`). 3. Apply the patch using the `patch` command, specifying the patch file. For example: `patch < /path/to/your/patch.diff`. 4. If you're building from source, run `make` to rebuild the KDE package with the applied changes. 5. Finally, install the patched version using `make install clean`. Always ensure you have backups and test the patched version before deploying it into a production environment.\",\n",
       " 'source': 'OWN_KNOWLEDGE'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentic_rag_v1('how patch KDE under FreeBSD?')\n",
    "# 'reasoning': 'The student is asking for a specific method to patch KDE under FreeBSD, and the context is currently empty...\n",
    "\n",
    "# 'action': 'ANSWER'\n",
    "# 'source': 'OWN_KNOWLEDGE'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff3a7ab-7e06-4d0c-8245-231be569e9a9",
   "metadata": {},
   "source": [
    "## STEP 6 - Agentic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3841e63-0c3d-49c1-b634-7a3aba2ac9ab",
   "metadata": {},
   "source": [
    "Part 2: Agentic search\n",
    "\n",
    "So far we had two actions only: search and answer.\n",
    "\n",
    "But we can let our \"agent\" formulate one or more search queries - and do it for a few iterations until we found an answer\n",
    "\n",
    "Let's build a prompt:\n",
    "\n",
    "List available actions:\n",
    "\n",
    "Search in FAQ\n",
    "\n",
    "-- Answer using own knowledge\n",
    "\n",
    "-- Answer using information extracted from FAQ\n",
    "\n",
    "-- Provide access to the previous actions\n",
    "\n",
    "Have clear stop criteria (no more than X iterations)\n",
    "\n",
    "We also specify the output format, so it's easier to parse it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acbb494e-f04c-481c-ac2d-bc946050b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deduplication function\n",
    "\n",
    "def dedup(seq):\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for el in seq:\n",
    "        _id = el['_id']\n",
    "        if _id in seen:\n",
    "            continue\n",
    "        seen.add(_id)\n",
    "        result.append(el)\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20a715a8-07c9-405c-b4d1-371510a09e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "\n",
    "The CONTEXT is build with the documents from our FAQ database.\n",
    "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
    "from FAQ to and add them to the context.\n",
    "PREVIOUS_ACTIONS contains the actions you already performed.\n",
    "\n",
    "At the beginning the CONTEXT is empty.\n",
    "\n",
    "You can perform the following actions:\n",
    "\n",
    "- Search in the FAQ database to get more data for the CONTEXT\n",
    "- Answer the question using the CONTEXT\n",
    "- Answer the question using your own knowledge\n",
    "\n",
    "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
    "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
    "\n",
    "Don't use search queries used at the previous iterations.\n",
    "\n",
    "Don't repeat previously performed actions.\n",
    "\n",
    "Don't perform more than {max_iterations} iterations for a given student question.\n",
    "The current iteration number: {iteration_number}. If we exceed the allowed number \n",
    "of iterations, give the best possible answer with the provided information.\n",
    "\n",
    "Output templates:\n",
    "\n",
    "If you want to perform search, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\",\n",
    "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER_CONTEXT\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<SEARCH_QUERIES>\n",
    "{search_queries}\n",
    "</SEARCH_QUERIES>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "<PREVIOUS_ACTIONS>\n",
    "{previous_actions}\n",
    "</PREVIOUS_ACTIONS>\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0b3478b-3a30-4c24-99f1-588368f33182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repetitive task - search, update context and search again if needed + delete duplicate results\n",
    "\n",
    "question = 'how do I do well on module 1'\n",
    "max_iterations = 3\n",
    "iteration_number = 0\n",
    "search_queries = []\n",
    "search_results  = []\n",
    "previous_actions = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e463cfa-2b6d-4259-a5ee-f48d8e97665f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 0. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I do well on module 1\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n"
     ]
    }
   ],
   "source": [
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=max_iterations,\n",
    "    iteration_number=iteration_number\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a93ee516-d289-4869-b6d2-8d84dc6e4579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n\"action\": \"SEARCH\",\\n\"reasoning\": \"The question is about how to perform well in a specific module, which might have strategies or guidelines in the FAQ. Searching for topics like \\'tips for success in module 1\\' or \\'how to excel in module 1\\' could provide relevant information.\",\\n\"keywords\": [\"tips for success in module 1\", \"how to excel in module 1\", \"module 1 study strategies\"]\\n}'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_json = llm(prompt)\n",
    "answer_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e5c688b-4670-4674-a10e-bd0a75e305e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 'SEARCH',\n",
       " 'reasoning': \"The question is about how to perform well in a specific module, which might have strategies or guidelines in the FAQ. Searching for topics like 'tips for success in module 1' or 'how to excel in module 1' could provide relevant information.\",\n",
       " 'keywords': ['tips for success in module 1',\n",
       "  'how to excel in module 1',\n",
       "  'module 1 study strategies']}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = json.loads(answer_json)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c1f14b8-9df2-455e-b279-06d2aa186aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tips for success in module 1',\n",
       " 'how to excel in module 1',\n",
       " 'module 1 study strategies']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_actions.append(answer)\n",
    "keywords = answer['keywords']\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee55f140-1237-4ac8-9e7d-ddbcbc2de2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have to search each keyword and add results to a context\n",
    "\n",
    "for kw in keywords:\n",
    "    search_queries.append(kw)\n",
    "    sr = search(kw)\n",
    "    search_results.extend(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42fa5520-8ac5-4717-8c38-4e6c218adb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\\nKrishna Anand',\n",
       "  'section': 'Module 5: pyspark',\n",
       "  'question': 'Module Not Found Error in Jupyter Notebook .',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 322},\n",
       " {'text': 'You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=‚Äù${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}‚Äù\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\\nAdditionally, you can check for the version of ‚Äòpy4j‚Äô of the spark you‚Äôre using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.',\n",
       "  'section': 'Module 5: pyspark',\n",
       "  'question': \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 323},\n",
       " {'text': \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\",\n",
       "  'section': 'Module 4: analytics engineering with dbt',\n",
       "  'question': \"DBT - Error: No module named 'pytz' while setting up dbt with docker\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 299},\n",
       " {'text': \"Issue:\\ne‚Ä¶\\nSolution:\\npip install psycopg2-binary\\nIf you already have it, you might need to update it:\\npip install psycopg2-binary --upgrade\\nOther methods, if the above fails:\\nif you are getting the ‚Äú ModuleNotFoundError: No module named 'psycopg2' ‚Äú error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\nFirst uninstall the psycopg package\\nThen update conda or pip\\nThen install psycopg again using pip.\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\",\n",
       "  'section': 'Module 1: Docker and Terraform',\n",
       "  'question': \"Postgres - ModuleNotFoundError: No module named 'psycopg2'\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 112},\n",
       " {'text': 'create_engine(\\'postgresql://root:root@localhost:5432/ny_taxi\\')  I get the error \"TypeError: \\'module\\' object is not callable\"\\nSolution:\\nconn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\\nengine = create_engine(conn_string)',\n",
       "  'section': 'Module 1: Docker and Terraform',\n",
       "  'question': \"Python - SQLALchemy - TypeError 'module' object is not callable\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 124}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see what we found\n",
    "\n",
    "search_results = dedup(search_results)\n",
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6026702-4a47-43c1-a90a-3bc38e7438d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_number = 2\n",
    "\n",
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=max_iterations,\n",
    "    iteration_number=iteration_number\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "36622fa1-aacf-4f4a-8ff7-2ef3a817a418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'SEARCH', 'reasoning': 'The context does not contain specific tips or strategies for excelling in Module 1. To provide a comprehensive answer, I will search for general study tips and advice related to performance in courses or modules, as these might be applicable to Module 1.', 'keywords': ['study tips for success', 'academic performance strategies', 'how to study effectively']}\n"
     ]
    }
   ],
   "source": [
    "answer_json = llm(prompt)\n",
    "answer = json.loads(answer_json)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "141d51c4-98ad-4238-8988-1d127880c5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION #0...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 0. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"To provide a thorough answer about the requirements for success in module 1, I need to gather information about the module's expectations, assessments, and study tips from FAQ documents.\",\n",
      "  \"keywords\": [\n",
      "    \"module 1 success tips\",\n",
      "    \"module 1 requirements\",\n",
      "    \"how to excel in module 1\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #1...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 1. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "how to excel in module 1\n",
      "module 1 requirements\n",
      "module 1 success tips\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=‚Äù${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}‚Äù\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‚Äòpy4j‚Äô of the spark you‚Äôre using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e‚Ä¶\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the ‚Äú ModuleNotFoundError: No module named 'psycopg2' ‚Äú error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Module ‚Äúkafka‚Äù not found when trying to run producer.py\n",
      "answer: Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\n",
      "To create a virtual env and install packages (run only once)\n",
      "python -m venv env\n",
      "source env/bin/activate\n",
      "pip install -r ../requirements.txt\n",
      "To activate it (you'll need to run it every time you need the virtual env):\n",
      "source env/bin/activate\n",
      "To deactivate it:\n",
      "deactivate\n",
      "This works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\n",
      "Also the virtual environment should be created only to run the python file. Docker images should first all be up and running.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To provide a thorough answer about the requirements for success in module 1, I need to gather information about the module's expectations, assessments, and study tips from FAQ documents.\", \"keywords\": [\"module 1 success tips\", \"module 1 requirements\", \"how to excel in module 1\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"To effectively answer the student's question about being successful in module 1, I need to gather specific information on the best practices, resources, and strategies tailored for that module from the FAQ database.\",\n",
      "  \"keywords\": [\n",
      "    \"module 1 study strategies\",\n",
      "    \"module 1 resources\",\n",
      "    \"how to succeed in module 1\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #2...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 2. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "how to succeed in module 1\n",
      "module 1 resources\n",
      "how to excel in module 1\n",
      "module 1 requirements\n",
      "module 1 study strategies\n",
      "module 1 success tips\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=‚Äù${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}‚Äù\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‚Äòpy4j‚Äô of the spark you‚Äôre using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e‚Ä¶\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the ‚Äú ModuleNotFoundError: No module named 'psycopg2' ‚Äú error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Module ‚Äúkafka‚Äù not found when trying to run producer.py\n",
      "answer: Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\n",
      "To create a virtual env and install packages (run only once)\n",
      "python -m venv env\n",
      "source env/bin/activate\n",
      "pip install -r ../requirements.txt\n",
      "To activate it (you'll need to run it every time you need the virtual env):\n",
      "source env/bin/activate\n",
      "To deactivate it:\n",
      "deactivate\n",
      "This works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\n",
      "Also the virtual environment should be created only to run the python file. Docker images should first all be up and running.\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: data-engineering-zoomcamp/week_6_stream_processing/python/resources/rides.csv is missing\n",
      "answer: Copy the file found in the Java example: data-engineering-zoomcamp/week_6_stream_processing/java/kafka_examples/src/main/resources/rides.csv\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: WSL - Insufficient system resources exist to complete the requested service.\n",
      "answer: Cause:\n",
      "It happens because the apps are not updated. To be specific, search for any pending updates for Windows Terminal, WSL and Windows Security updates.\n",
      "Solution\n",
      "for updating Windows terminal which worked for me:\n",
      "Go to Microsoft Store.\n",
      "Go to the library of apps installed in your system.\n",
      "Search for Windows terminal.\n",
      "Update the app and restart your system to  see the changes.\n",
      "For updating the Windows security updates:\n",
      "Go to Windows updates and check if there are any pending updates from Windows, especially security updates.\n",
      "Do restart your system once the updates are downloaded and installed successfully.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook‚Äôs cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module ‚Äúpsycopg2‚Äù. Can be installed by Conda or pip.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To provide a thorough answer about the requirements for success in module 1, I need to gather information about the module's expectations, assessments, and study tips from FAQ documents.\", \"keywords\": [\"module 1 success tips\", \"module 1 requirements\", \"how to excel in module 1\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To effectively answer the student's question about being successful in module 1, I need to gather specific information on the best practices, resources, and strategies tailored for that module from the FAQ database.\", \"keywords\": [\"module 1 study strategies\", \"module 1 resources\", \"how to succeed in module 1\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"ANSWER\",\n",
      "  \"answer\": \"To be successful in Module 1 on Docker and Terraform, you should focus on several key areas: \\n\\n1. **Understanding Core Concepts**: Ensure you grasp the fundamental concepts of Docker and Terraform, including containerization principles, how to create and manage Docker containers, and Infrastructure as Code (IaC) principles with Terraform.\\n\\n2. **Hands-On Practice**: Engage in hands-on exercises and labs provided during the module. Setting up Docker and running Terraform scripts in a practice environment will solidify your understanding.\\n\\n3. **Follow Instructions Closely**: Pay attention to the setup and installation instructions, especially regarding required dependencies, as common issues often arise from incorrect configurations.\\n\\n4. **Utilize Available Resources**: Make use of any supplementary resources provided in the module, such as videos, documentation, or tutorials, to broaden your knowledge and understanding of the tools.\\n\\n5. **Ask Questions**: Don't hesitate to reach out to instructors or fellow classmates if you're facing challenges or have questions about specific topics.\\n\\n6. **Review Frequently**: Regularly review materials covered to reinforce your understanding and retention of the concepts.\\n\\n7. **Stay Updated**: Ensure your development environment is up to date, including installations of Docker and Terraform, as outdated versions can lead to compatibility and functionality issues.\\n\\nBy combining these strategies with consistent effort and engagement, you will enhance your chances of success in Module 1.\",\n",
      "  \"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# now lets create a function which will perform a search in a loop\n",
    "\n",
    "question = \"what do I need to do to be successful at module 1?\"\n",
    "\n",
    "search_queries = []\n",
    "search_results = []\n",
    "previous_actions = []\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "while True:\n",
    "    print(f'ITERATION #{iteration}...')\n",
    "\n",
    "    context = build_context(search_results)\n",
    "    prompt = prompt_template.format(\n",
    "        question=question,\n",
    "        context=context,\n",
    "        search_queries=\"\\n\".join(search_queries),\n",
    "        previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "        max_iterations=3,\n",
    "        iteration_number=iteration\n",
    "    )\n",
    "\n",
    "    print(prompt)\n",
    "\n",
    "    answer_json = llm(prompt)\n",
    "    answer = json.loads(answer_json)\n",
    "    print(json.dumps(answer, indent=2))\n",
    "\n",
    "    previous_actions.append(answer)\n",
    "\n",
    "    action = answer['action']\n",
    "    if action != 'SEARCH':\n",
    "        break\n",
    "\n",
    "    keywords = answer['keywords']\n",
    "    search_queries = list(set(search_queries) | set(keywords))\n",
    "    \n",
    "    for k in keywords:\n",
    "        res = search(k)\n",
    "        search_results.extend(res)\n",
    "\n",
    "    search_results = dedup(search_results)\n",
    "    \n",
    "    iteration = iteration + 1\n",
    "    if iteration >= 4:\n",
    "        break\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b370b760-00b6-4a9f-a871-6b2534e796a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be successful in Module 1 on Docker and Terraform, you should focus on several key areas: \n",
      "\n",
      "1. **Understanding Core Concepts**: Ensure you grasp the fundamental concepts of Docker and Terraform, including containerization principles, how to create and manage Docker containers, and Infrastructure as Code (IaC) principles with Terraform.\n",
      "\n",
      "2. **Hands-On Practice**: Engage in hands-on exercises and labs provided during the module. Setting up Docker and running Terraform scripts in a practice environment will solidify your understanding.\n",
      "\n",
      "3. **Follow Instructions Closely**: Pay attention to the setup and installation instructions, especially regarding required dependencies, as common issues often arise from incorrect configurations.\n",
      "\n",
      "4. **Utilize Available Resources**: Make use of any supplementary resources provided in the module, such as videos, documentation, or tutorials, to broaden your knowledge and understanding of the tools.\n",
      "\n",
      "5. **Ask Questions**: Don't hesitate to reach out to instructors or fellow classmates if you're facing challenges or have questions about specific topics.\n",
      "\n",
      "6. **Review Frequently**: Regularly review materials covered to reinforce your understanding and retention of the concepts.\n",
      "\n",
      "7. **Stay Updated**: Ensure your development environment is up to date, including installations of Docker and Terraform, as outdated versions can lead to compatibility and functionality issues.\n",
      "\n",
      "By combining these strategies with consistent effort and engagement, you will enhance your chances of success in Module 1.\n"
     ]
    }
   ],
   "source": [
    "print(answer['answer']) # for better look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62c2b829-d498-4755-bfda-321fbeffc9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6371ca73-3c02-48cb-8717-9222c2e09465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put together agentic search as a function\n",
    "\n",
    "def agentic_search(question):\n",
    "    search_queries = []\n",
    "    search_results = []\n",
    "    previous_actions = []\n",
    "\n",
    "    iteration = 0\n",
    "    \n",
    "    while True:\n",
    "        print(f'ITERATION #{iteration}...')\n",
    "    \n",
    "        context = build_context(search_results)\n",
    "        prompt = prompt_template.format(\n",
    "            question=question,\n",
    "            context=context,\n",
    "            search_queries=\"\\n\".join(search_queries),\n",
    "            previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "            max_iterations=3,\n",
    "            iteration_number=iteration\n",
    "        )\n",
    "    \n",
    "        print(prompt)\n",
    "    \n",
    "        answer_json = llm(prompt)\n",
    "        answer = json.loads(answer_json)\n",
    "        print(json.dumps(answer, indent=2))\n",
    "\n",
    "        previous_actions.append(answer)\n",
    "    \n",
    "        action = answer['action']\n",
    "        if action != 'SEARCH':\n",
    "            break\n",
    "    \n",
    "        keywords = answer['keywords']\n",
    "        search_queries = list(set(search_queries) | set(keywords))\n",
    "\n",
    "        for k in keywords:\n",
    "            res = search(k)\n",
    "            search_results.extend(res)\n",
    "    \n",
    "        search_results = dedup(search_results)\n",
    "        \n",
    "        iteration = iteration + 1\n",
    "        if iteration >= 4:\n",
    "            break\n",
    "    \n",
    "        print()\n",
    "\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "10863975-d00a-417b-afd1-a980c0dbb66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION #0...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 0. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I prepare for the course?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"To provide a comprehensive answer on how to prepare for the course, I need to gather specific information from the FAQ database about preparation strategies, resources, and tips provided for students.\",\n",
      "  \"keywords\": [\n",
      "    \"course preparation tips\",\n",
      "    \"how to prepare for the course\",\n",
      "    \"resources for course preparation\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #1...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 1. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I prepare for the course?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "how to prepare for the course\n",
      "resources for course preparation\n",
      "course preparation tips\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  ‚ÄúOffice Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don‚Äôt forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a ‚Äúlive‚Äù cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Is it possible to use tool ‚ÄúX‚Äù instead of the one tool you use in the course?\n",
      "answer: Yes, this applies if you want to use Airflow or Prefect instead of Mage, AWS or Snowflake instead of GCP products or Tableau instead of Metabase or Google data studio.\n",
      "The course covers 2 alternative data stacks, one using GCP and one using local installation of everything. You can use one of them or use your tool of choice.\n",
      "Should you consider it instead of the one tool you use? That we can‚Äôt support you if you choose to use a different stack, also you would need to explain the different choices of tool for the peer review of your capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors‚Äô code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: data-engineering-zoomcamp/week_6_stream_processing/python/resources/rides.csv is missing\n",
      "answer: Copy the file found in the Java example: data-engineering-zoomcamp/week_6_stream_processing/java/kafka_examples/src/main/resources/rides.csv\n",
      "\n",
      "section: General course-related questions\n",
      "question: Any books or additional resources you recommend?\n",
      "answer: Yes to both! check out this document: https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/awesome-data-engineering.md\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To provide a comprehensive answer on how to prepare for the course, I need to gather specific information from the FAQ database about preparation strategies, resources, and tips provided for students.\", \"keywords\": [\"course preparation tips\", \"how to prepare for the course\", \"resources for course preparation\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"Since the previous search might not have yielded specific details on preparation strategies, I'm looking for targeted information regarding study techniques, recommended resources, and any tips mentioned in the FAQ documents about preparing for the course.\",\n",
      "  \"keywords\": [\n",
      "    \"study techniques for course\",\n",
      "    \"recommended resources for course preparation\",\n",
      "    \"tips for succeeding in the course\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #2...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 2. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I prepare for the course?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "how to prepare for the course\n",
      "study techniques for course\n",
      "resources for course preparation\n",
      "course preparation tips\n",
      "tips for succeeding in the course\n",
      "recommended resources for course preparation\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  ‚ÄúOffice Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don‚Äôt forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a ‚Äúlive‚Äù cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Is it possible to use tool ‚ÄúX‚Äù instead of the one tool you use in the course?\n",
      "answer: Yes, this applies if you want to use Airflow or Prefect instead of Mage, AWS or Snowflake instead of GCP products or Tableau instead of Metabase or Google data studio.\n",
      "The course covers 2 alternative data stacks, one using GCP and one using local installation of everything. You can use one of them or use your tool of choice.\n",
      "Should you consider it instead of the one tool you use? That we can‚Äôt support you if you choose to use a different stack, also you would need to explain the different choices of tool for the peer review of your capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors‚Äô code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: data-engineering-zoomcamp/week_6_stream_processing/python/resources/rides.csv is missing\n",
      "answer: Copy the file found in the Java example: data-engineering-zoomcamp/week_6_stream_processing/java/kafka_examples/src/main/resources/rides.csv\n",
      "\n",
      "section: General course-related questions\n",
      "question: Any books or additional resources you recommend?\n",
      "answer: Yes to both! check out this document: https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/awesome-data-engineering.md\n",
      "\n",
      "section: General course-related questions\n",
      "question: Environment - Is Python 3.9 still the recommended version to use in 2024?\n",
      "answer: Yes, for simplicity (of troubleshooting against the recorded videos) and stability. [source]\n",
      "But Python 3.10 and 3.11 should work fine.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To provide a comprehensive answer on how to prepare for the course, I need to gather specific information from the FAQ database about preparation strategies, resources, and tips provided for students.\", \"keywords\": [\"course preparation tips\", \"how to prepare for the course\", \"resources for course preparation\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"Since the previous search might not have yielded specific details on preparation strategies, I'm looking for targeted information regarding study techniques, recommended resources, and any tips mentioned in the FAQ documents about preparing for the course.\", \"keywords\": [\"study techniques for course\", \"recommended resources for course preparation\", \"tips for succeeding in the course\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"ANSWER_CONTEXT\",\n",
      "  \"answer\": \"To prepare for the course, it's beneficial to check out the document that lists recommended resources, including books and additional materials, which can be found [here](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/awesome-data-engineering.md). Additionally, you should register for the course before it starts and join the necessary channels like the course Telegram channel for announcements. Participating in the live office hours at the start can also provide a good foundation for your studies. You can continue to access all course materials even after it finishes, allowing you to study at your own pace as needed.\",\n",
      "  \"source\": \"CONTEXT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# and test our agentic search function\n",
    "\n",
    "answer = agentic_search('how do I prepare for the course?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eefe355a-e1eb-473c-a94e-de6f191bc4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'ANSWER_CONTEXT', 'answer': \"To prepare for the course, it's beneficial to check out the document that lists recommended resources, including books and additional materials, which can be found [here](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/awesome-data-engineering.md). Additionally, you should register for the course before it starts and join the necessary channels like the course Telegram channel for announcements. Participating in the live office hours at the start can also provide a good foundation for your studies. You can continue to access all course materials even after it finishes, allowing you to study at your own pace as needed.\", 'source': 'CONTEXT'}\n"
     ]
    }
   ],
   "source": [
    "# for better formatting\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c5dff8c5-7f8d-48b2-978e-98cb00be9a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To prepare for the course, it's beneficial to check out the document that lists recommended resources, including books and additional materials, which can be found [here](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/awesome-data-engineering.md). Additionally, you should register for the course before it starts and join the necessary channels like the course Telegram channel for announcements. Participating in the live office hours at the start can also provide a good foundation for your studies. You can continue to access all course materials even after it finishes, allowing you to study at your own pace as needed.\n"
     ]
    }
   ],
   "source": [
    "# no need of parsing json?\n",
    "# answer = json.loads(answer)\n",
    "\n",
    "print(answer['answer'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b7da6d-c060-41ac-ac61-f53c6bcccef9",
   "metadata": {},
   "source": [
    "## STEP 7 - Function calling (\"tool use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8876c3d7-f38e-48ab-adf0-5d6307001090",
   "metadata": {},
   "source": [
    "Part 3: Function calling - code from\n",
    "https://github.com/alexeygrigorev/rag-agents-workshop/tree/main\n",
    "\n",
    "Function calling in OpenAI\n",
    "\n",
    "We put all this logic inside our prompt.\n",
    "\n",
    "But OpenAI and other providers provide a convenient API for adding extra functionality like search.\n",
    "\n",
    "https://platform.openai.com/docs/guides/function-calling\n",
    "\n",
    "It's called \"function calling\" - you define functions that the model can call, and if it decides to make a call, it returns structured output for that.\n",
    "\n",
    "For example, let's take our search function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a38727b-9713-453f-a5da-5cd071fef0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search tool\n",
    "\n",
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a953f43-55fc-4aa3-9ea4-747b9c7e2325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': \"Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\\nTo create a virtual env and install packages (run only once)\\npython -m venv env\\nsource env/bin/activate\\npip install -r ../requirements.txt\\nTo activate it (you'll need to run it every time you need the virtual env):\\nsource env/bin/activate\\nTo deactivate it:\\ndeactivate\\nThis works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\\nAlso the virtual environment should be created only to run the python file. Docker images should first all be up and running.\", 'section': 'Module 6: streaming with kafka', 'question': 'Module ‚Äúkafka‚Äù not found when trying to run producer.py', 'course': 'data-engineering-zoomcamp', '_id': 372}, {'text': \"Below I have listed some steps I took to rectify this and potentially other minor errors, in Windows:\\nUse the git bash terminal in windows.\\nActivate python venv from git bash: source .venv/Scripts/activate\\nModify the seed_kafka.py file: in the first line, replace python3 with python.\\nNow from git bash, run the seed-kafka cmd. It should work now.\\nAdditional Notes:\\nYou can connect to the RisingWave cluster from Powershell with the command psql -h localhost -p 4566 -d dev -U root , otherwise it asks for a password.\\nThe equivalent of source commands.sh  in Powershell is . .\\\\commands.sh from the workshop directory.\\nHope this can save you from some trouble in case you're doing this workshop on Windows like I am.\\n‚Äî--------------------------------------------------------------------------------------\", 'section': 'Workshop 2 - RisingWave', 'question': 'Psycopg2 InternalError: Failed to run the query - when running the seed-kafka command after initial setup.', 'course': 'data-engineering-zoomcamp', '_id': 425}, {'text': 'In the project directory, run:\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java', 'section': 'Module 6: streaming with kafka', 'question': 'Java Kafka: How to run producer/consumer/kstreams/etc in terminal', 'course': 'data-engineering-zoomcamp', '_id': 389}, {'text': 'If you have this error, it most likely that your kafka broker docker container is not working.\\nUse docker ps to confirm\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.', 'section': 'Module 6: streaming with kafka', 'question': 'kafka.errors.NoBrokersAvailable: NoBrokersAvailable', 'course': 'data-engineering-zoomcamp', '_id': 379}, {'text': 'In my set up, all of the dependencies listed in gradle.build were not installed in <project_name>-1.0-SNAPSHOT.jar.\\nSolution:\\nIn build.gradle file, I added the following at the end:\\nshadowJar {\\narchiveBaseName = \"java-kafka-rides\"\\narchiveClassifier = \\'\\'\\n}\\nAnd then in the command line ran ‚Äògradle shadowjar‚Äô, and run the script from java-kafka-rides-1.0-SNAPSHOT.jar created by the shadowjar', 'section': 'Module 6: streaming with kafka', 'question': 'Java Kafka: <project_name>-1.0-SNAPSHOT.jar errors: package xxx does not exist even after gradle build', 'course': 'data-engineering-zoomcamp', '_id': 387}]\n"
     ]
    }
   ],
   "source": [
    "answer = search(\"How to run Kafka in Docker\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4868ba76-c685-4003-bfa5-6ac3207940d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to describe our search function for OpenAI / Pydantic:\n",
    "# (this is a json wrapper to use our minsearch function = search tool from above ))\n",
    "\n",
    "search_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"search\",\n",
    "    \"description\": \"Search the FAQ database\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Search query text to look up in the course FAQ.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "# \"name\": \"search\" - based on this Python will call search(query) from above\n",
    "# and pass a property \"query\": { \"type\": \"string\" ... when / into this function call object is created?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "af8d97c9-d74f-4c07-b0dc-57b081370ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseFunctionToolCall(arguments='{\"query\":\"module 1 tips\"}', call_id='call_gm8iAv1NXFfVaQDbAhoG0GUW', name='search', type='function_call', id='fc_68bbf1618c9c8191bb83d422c7c274840b5bbd3fb51d7310', status='completed')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we have:\n",
    "\n",
    "# name: search\n",
    "# description: when to use it\n",
    "# parameters: all the arguments that the function can take and their description\n",
    "# In order to use function calling, we'll use a newer API - the \"responses\" API (not \"chat completions\" as previously):\n",
    "\n",
    "question = \"How do I do well in module 1?\"\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\"\"\".strip()\n",
    "\n",
    "tools = [search_tool]\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "response.output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5844bbe7-f856-4290-ae6c-20c72ced21c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseFunctionToolCall(arguments='{\"query\":\"module 1 tips\"}', call_id='call_gm8iAv1NXFfVaQDbAhoG0GUW', name='search', type='function_call', id='fc_68bbf1618c9c8191bb83d422c7c274840b5bbd3fb51d7310', status='completed')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's make a call to search - to the earlier minsearch << def search(query) >> function:\n",
    "# to the index object which is <minsearch.append.AppendableIndex at 0x7473af0c0cb0> \n",
    "\n",
    "calls = response.output\n",
    "call = calls[0]\n",
    "call\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0ee7e628-ed6f-4ff8-b7d0-0c4c930dd8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'call_gm8iAv1NXFfVaQDbAhoG0GUW'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_id = call.call_id\n",
    "call_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e3322b8d-c26d-4c78-bffb-6e8fb634b47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_name = call.name\n",
    "f_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "73a9f755-eb72-45fc-bcb0-14c997569cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'module 1 tips'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments = json.loads(call.arguments)\n",
    "arguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b8e1558c-b31f-4852-848d-9d9abac56aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.search(query)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nice Python trick - use globals() function which knows all variables and functions in our enviromnent\n",
    "\n",
    "globals()[f_name] # which is f_name = call.name\n",
    "# <function __main__.search(query)> - this is our minsearch function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9fe77e32-c28f-482c-b9aa-e87e51b6b741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'name': 'search',\n",
       " 'description': 'Search the FAQ database',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'query': {'type': 'string',\n",
       "    'description': 'Search query text to look up in the course FAQ.'}},\n",
       "  'required': ['query'],\n",
       "  'additionalProperties': False}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()[\"search_tool\"] \n",
    "# prints our dictionary we use to talk to openAI function calling interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "83b7123c-d8bc-4783-a11a-2ffc8af3b223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'module 1 tips'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# essentially using globals() we can call any function and pass arguments\n",
    "arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dbf377e4-83df-42ed-a385-57a6ffe57763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=‚Äù${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}‚Äù\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\\nAdditionally, you can check for the version of ‚Äòpy4j‚Äô of the spark you‚Äôre using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.',\n",
       "  'section': 'Module 5: pyspark',\n",
       "  'question': \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 323},\n",
       " {'text': \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\",\n",
       "  'section': 'Module 4: analytics engineering with dbt',\n",
       "  'question': \"DBT - Error: No module named 'pytz' while setting up dbt with docker\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 299},\n",
       " {'text': 'Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\\nKrishna Anand',\n",
       "  'section': 'Module 5: pyspark',\n",
       "  'question': 'Module Not Found Error in Jupyter Notebook .',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 322},\n",
       " {'text': \"Issue:\\ne‚Ä¶\\nSolution:\\npip install psycopg2-binary\\nIf you already have it, you might need to update it:\\npip install psycopg2-binary --upgrade\\nOther methods, if the above fails:\\nif you are getting the ‚Äú ModuleNotFoundError: No module named 'psycopg2' ‚Äú error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\nFirst uninstall the psycopg package\\nThen update conda or pip\\nThen install psycopg again using pip.\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\",\n",
       "  'section': 'Module 1: Docker and Terraform',\n",
       "  'question': \"Postgres - ModuleNotFoundError: No module named 'psycopg2'\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 112},\n",
       " {'text': \"Error raised during the jupyter notebook‚Äôs cell execution:\\nengine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\\nSolution: Need to install Python module ‚Äúpsycopg2‚Äù. Can be installed by Conda or pip.\",\n",
       "  'section': 'Module 1: Docker and Terraform',\n",
       "  'question': \"Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 125}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = globals()[f_name]\n",
    "f(**arguments) # here we call our minsearch search function to find 5 'module 1 tips' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa45990b-7b54-4076-8f7e-b7e23ba2f3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff344490-394e-479f-bc97-17882476d056",
   "metadata": {},
   "source": [
    "## STEP 0 - install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3366dc0c-7a3d-4955-9b84-b4d06301c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to enter OpenAI key here and then we can run all cells freely...\n",
    "import os\n",
    "from getpass import getpass\n",
    "from openai import OpenAI\n",
    "\n",
    "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
    "    openai_api_key = getpass(\"üîë Enter your OpenAI API key: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9206afd3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# source is https://www.youtube.com/watch?v=GH3lrOsU3AU\n",
    "# and notebook is https://github.com/DataTalksClub/llm-zoomcamp/blob/main/0a-agents/notebook.ipynb\n",
    "# Follow along this tutorial: https://github.com/alexeygrigorev/rag-agents-workshop\n",
    "\n",
    "# STEP 0 - installing packages we need here and in the VS code terminal:\n",
    "\n",
    "# Run in VS code terminal:\n",
    "# pip install --upgrade pip # no reminders after!\n",
    "# pip install tqdm notebook==7.1.2 openai elasticsearch==8.13.0 pandas scikit-learn ipywidgets\n",
    "# jupyter notebook # to run jupyter engine locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4e37acb-1feb-4da5-9ab5-b35d80df1171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install minsearch -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e675499-6969-48f7-b42a-3b51a37c3516",
   "metadata": {},
   "source": [
    "## STEP 1 - download evaluation data from Github and build in-memory search index with minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d23e682f-5025-448e-9687-28e26d0fce22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Problem description\\nInfrastructure created in AWS with CD-Deploy Action needs to be destroyed\\nSolution description\\nFrom local:\\nterraform init -backend-config=\"key=mlops-zoomcamp-prod.tfstate\" --reconfigure\\nterraform destroy --var-file vars/prod.tfvars\\nAdded by Erick Calderin',\n",
       " 'section': 'Module 6: Best practices',\n",
       " 'question': 'How to destroy infrastructure created via GitHub Actions',\n",
       " 'course': 'mlops-zoomcamp'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download our FAQ dataset\n",
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "documents[-1] # to see a format of downloaded FAQ dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d7c1561-c33b-4817-9160-0d659cd8102e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x74a4480ba540>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build index - takes a few seconds with minsearch\n",
    "\n",
    "from minsearch import AppendableIndex\n",
    "\n",
    "index = AppendableIndex(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d58d90-b092-4318-9daf-5c22ed75bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a search function with weights: boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "# number of results 5 and course is hard coded here  - filter_dict={'course': 'data-engineering-zoomcamp'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee44aa1e-eb04-436a-bd70-c944c625b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Can I still join the course?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "526dec30-411e-4965-8c95-8fa2f136cb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I still join the course after the start date?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 2},\n",
       " {'text': \"No, you can only get a certificate if you finish the course with a ‚Äúlive‚Äù cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Certificate - Can I follow the course in a self-paced mode and get a certificate?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 11},\n",
       " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 7},\n",
       " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  ‚ÄúOffice Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon‚Äôt forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 0},\n",
       " {'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 3}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if our search function works \n",
    "\n",
    "search(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53aa958-7f3d-4366-a8d8-77f5eeb644e1",
   "metadata": {},
   "source": [
    "## STEP 2 - build prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10a7ef93-818e-4e91-9f57-52b34c7c6e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a prompt\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2c19daf-7c13-4a5e-a202-e92fe9871560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
      "Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "\n",
      "<QUESTION>\n",
      "Can I still join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT>\n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a ‚Äúlive‚Äù cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  ‚ÄúOffice Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don‚Äôt forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?\n",
      "answer: You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\n",
      "\n",
      "\n",
      "</CONTEXT>\n"
     ]
    }
   ],
   "source": [
    "# test how our prompt build works by calling search(question)\n",
    "\n",
    "prompt = build_prompt(question, search(question))\n",
    "print(prompt) # better formatted for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1437dbe4-a21b-4d5b-b38c-fcb1c2a65faa",
   "metadata": {},
   "source": [
    "## STEP 3 - Connect to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "310bba81-83a1-45e9-a3c7-49be5bd834b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to LLM, we entered our API KEY already at the first cell\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8959bb41-fe64-4a0c-a513-09193cc1ff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = search(question)\n",
    "# just repeating step 1 - keyword search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f68040dd-3e23-4a44-8d55-30f651bce87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = build_prompt(question, search_results)\n",
    "# repeating step 2 - building prompt on top of search results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92bf5fd8-fa18-4c07-b8c3-96eaaada704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to send our prompt to llm \n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56cbbc89-489a-439f-886e-8c83fc3e1838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you can still join the course even after the start date. Even if you don't register, you're eligible to submit the homework. However, be aware that there will be deadlines for turning in the final projects, so it's advisable not to leave everything to the last minute.\n"
     ]
    }
   ],
   "source": [
    "# test if our llm can answer something meaningful based on prompt provided\n",
    "\n",
    "answer = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ada0a00b-186c-4ada-b4a8-a1b1732e81e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
      "Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "\n",
      "<QUESTION>\n",
      "Can I still join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT>\n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a ‚Äúlive‚Äù cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  ‚ÄúOffice Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don‚Äôt forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?\n",
      "answer: You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\n",
      "\n",
      "\n",
      "</CONTEXT>\n"
     ]
    }
   ],
   "source": [
    "print(prompt) # this is what we have sent to llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870cb933-452c-41f3-b99c-44c72bc0af59",
   "metadata": {},
   "source": [
    "## STEP 4 - assemble our RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71781bd1-7beb-4ad4-8ab8-5c15ddd7e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is our RAG pipeline\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "003417eb-7010-48af-bdbc-02da09f89fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but it appears that there is no relevant information provided in the context regarding how to patch KDE under FreeBSD. Please check the official documentation or community forums for guidance on this topic.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test by irrelevant question - something which is NOT in FAQ\n",
    "\n",
    "rag(\"How do I patch KDE under FreeBSD?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1788745b-4d66-4458-9e01-238b33536efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The context provided does not contain any information regarding what Shakespeare said about peeling a carrot. Therefore, I am unable to answer that question.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"What Shakespeare said about peeling a carrot?\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "321524b2-58ec-49a0-a6e5-0984cc69dcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To run Kafka in Docker, first ensure that your Kafka broker Docker container is working. You can confirm this by running the command `docker ps`. If the container is not running, navigate to the folder containing your Docker Compose YAML file and execute `docker compose up -d` to start all the instances. This will set up the necessary services for Kafka to run.\n"
     ]
    }
   ],
   "source": [
    "# relevant question - it actually was in FAQ\n",
    "answer = rag(\"How to run Kafka in Docker\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37a06640-c69c-4799-b4e6-8ce236fae194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patching KDE under FreeBSD involves several steps, including downloading the relevant patches, applying them to the source code, and then rebuilding the software. Below is a general guide on how to do this:\n",
      "\n",
      "### Step 1: Install Required Tools\n",
      "You should ensure you have the necessary tools for building software on FreeBSD. You can do this by installing the FreeBSD ports collection and other essential tools.\n",
      "\n",
      "You can install the `ports` tree if you haven't already:\n",
      "```sh\n",
      "pkg install portsnap\n",
      "portsnap fetch update\n",
      "```\n",
      "\n",
      "### Step 2: Download KDE Ports\n",
      "If you want to patch a specific version of KDE, navigate to the relevant ports directory. For example, if you're looking to patch KDE Plasma, you'd go to the `x11/kde5` directory:\n",
      "```sh\n",
      "cd /usr/ports/x11/kde5\n",
      "```\n",
      "\n",
      "### Step 3: Applying the Patch\n",
      "1. **Download the Patch:** Acquire the patch you want to apply. This might be from the KDE website, a Git repository, or a mailing list. The patch file will typically be a `.diff` or `.patch` file.\n",
      "\n",
      "2. **Applying the Patch:** Use the `patch` command to apply the patch to the source files. Assuming your patch file is named `my_patch.patch`:\n",
      "   ```sh\n",
      "   patch -p1 < /path/to/my_patch.patch\n",
      "   ```\n",
      "\n",
      "   Make sure to run this command in the KDE source directory (`/usr/ports/x11/kde5` or the specific KDE application directory).\n",
      "\n",
      "### Step 4: Build the Software\n",
      "After applying the patch, build the KDE software. You can navigate to the port directory and use the `make` command:\n",
      "```sh\n",
      "make install clean\n",
      "```\n",
      "You might also want to use the `make` command with the `-DBATCH` option to reduce user interaction during the build:\n",
      "```sh\n",
      "make -DBATCH install clean\n",
      "```\n",
      "\n",
      "### Step 5: Test the Changes\n",
      "Once the software has been built and installed, test the KDE environment to ensure that the patch has been correctly applied and that everything is functioning as expected.\n",
      "\n",
      "### Step 6: Maintain the Patch (If Necessary)\n",
      "If you plan on keeping the patch for future updates, consider storing it in a version control system or documenting the changes you made so you can reapply them as needed.\n",
      "\n",
      "### Additional Tips\n",
      "- **Refer to Documentation:** Always refer to the FreeBSD Handbook and the specific KDE ports documentation for additional details or troubleshooting.\n",
      "- **Backup:** Before applying patches or making changes, consider backing up your current working environment to avoid issues.\n",
      "- **Use a Virtual Machine:** If you‚Äôre unsure about the effects of a patch, consider testing it in a virtual machine or a separate environment.\n",
      "\n",
      "By following these steps, you should be able to successfully patch KDE under FreeBSD.\n"
     ]
    }
   ],
   "source": [
    "# LLM by itself know the answer, but our RAG is prohibiting it\n",
    "# above rag(\"How do I patch KDE under FreeBSD?\") returned nothing, but - \n",
    "print(llm(\"How do I patch KDE under FreeBSD?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9eb3baa8-7046-4262-a63e-4b304fe0ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually this was the main idea for STEP 5 below - if llm can answer question by itself, nice!\n",
    "# if not - it should be able to search our FAQ database and build the context for answer..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f64f5c-3f07-4f42-aac4-ef1aa7b2a98b",
   "metadata": {},
   "source": [
    "## STEP 5 - \"Agentic\" RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "869f1f09-7145-49ee-a222-d173457b20ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# essentially we only modify our prompt - so llm can decide either to give an answer immediately\n",
    "# or use a SEARCH tool to get more CONTEXT from our FAQ\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "At the beginning the context is EMPTY.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "If CONTEXT is EMPTY, you can use our FAQ database.\n",
    "In this case, use the following output template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\"\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75385600-f09c-444a-8189-00d450e3321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Can I still join the course?'\n",
    "context = 'EMPTY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9642963-cdde-472e-b98b-1a134cc4b98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "Can I still join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "EMPTY\n",
      "</CONTEXT>\n",
      "\n",
      "If CONTEXT is EMPTY, you can use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(question=question, context=context)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d2c6d4e-5dfb-473c-a0c5-a655849e90db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n\"action\": \"SEARCH\",\\n\"reasoning\": \"The context is empty, and I need to verify if there are any specific deadlines or requirements for joining the course. Checking the FAQ database will provide accurate information regarding course enrollment.\"\\n}'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_json = llm(prompt)\n",
    "answer_json \n",
    "# model decided to use \"SEARCH\" function because CONTEXT is empty\n",
    "# and provided a reason for it  - \"reasoning\": \"I am unsure about the specific enrollment dates..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b60d4dfe-ad36-4e86-a873-43c123206642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SEARCH'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# we can parse the llm answer and use tool if appropriate:\n",
    "\n",
    "answer = json.loads(answer_json)\n",
    "answer['action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d71f231-1936-48ec-a271-e77a83823e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets ask LLM something it knows already well:\n",
    "question = 'Can I run Docker on Windows 10?'\n",
    "context = 'EMPTY'\n",
    "prompt = prompt_template.format(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f1e9aa1-c624-4c31-b23a-4796fe243aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n\"action\": \"ANSWER\",\\n\"answer\": \"Yes, you can run Docker on Windows 10. Docker provides a version called Docker Desktop that is specifically designed for Windows 10. You\\'ll need to ensure that your system meets the requirements, such as having a supported edition of Windows (Pro, Enterprise, or Education) and that virtualization is enabled in your BIOS. Once you install Docker Desktop, you\\'ll be able to create and manage containers directly on your Windows environment.\",\\n\"source\": \"OWN_KNOWLEDGE\"\\n}'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_json = llm(prompt)\n",
    "answer_json \n",
    "# it provides answer immediately - zero shot - action\": \"ANSWER\":\n",
    "# and says it knows it already - \"source\": \"OWN_KNOWLEDGE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c445f22-9ca0-4d4d-b5dc-84dfcaaaff42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ANSWER'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = json.loads(answer_json)\n",
    "answer['action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b107c7e-5b1d-4862-821b-edc3cb9be37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if model says SEARCH then we need to use a search tool and build context + update prompt\n",
    "\n",
    "def build_context(search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    return context.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b6c1333-832a-4378-b322-84c24611982b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "Can I still join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a ‚Äúlive‚Äù cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  ‚ÄúOffice Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don‚Äôt forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?\n",
      "answer: You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\n",
      "</CONTEXT>\n",
      "\n",
      "If CONTEXT is EMPTY, you can use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# asking something it should search for:\n",
    "question = 'Can I still join the course?'\n",
    "\n",
    "search_results = search(question)\n",
    "context = build_context(search_results)\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "print(prompt) # for better formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6e63838-4743-4629-b5ff-5e20e4b137ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"Yes, you can still join the course even after the start date. You'll be able to submit homework, but please keep in mind that there will be deadlines for final projects, so it's best not to leave your work until the last minute.\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# lets ask llm after we performed the search as advised and updated llm context\n",
    "\n",
    "answer_json = llm(prompt)\n",
    "print(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "653e62b3-403f-4766-a302-32b224cd7c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to put everything together and parse our response json automatically\n",
    "# algo - if \"action\": \"SEARCH\" then llm uses our FAQ search tool\n",
    "# if \"action\": \"ANSWER\" - then it answers immediately ...\n",
    "\n",
    "def agentic_rag_v1(question):\n",
    "    context = \"EMPTY\"\n",
    "    prompt = prompt_template.format(question=question, context=context)\n",
    "    answer_json = llm(prompt)\n",
    "    answer = json.loads(answer_json)\n",
    "    print(answer)\n",
    "\n",
    "    if answer['action'] == 'SEARCH':\n",
    "        print('need to perform search...')\n",
    "        search_results = search(question)\n",
    "        context = build_context(search_results)\n",
    "        \n",
    "        prompt = prompt_template.format(question=question, context=context)\n",
    "        answer_json = llm(prompt)\n",
    "        answer = json.loads(answer_json)\n",
    "        print(answer)\n",
    "\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b8617e7-653c-4f9c-a952-0e4321bfb2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'ANSWER', 'answer': \"To join the course, please visit the course website and look for the enrollment section. You'll typically need to create an account or log in if you already have one. Then, follow the steps to register for the course you are interested in. If you have any issues, you can contact the course administration for further assistance.\", 'source': 'OWN_KNOWLEDGE'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': \"To join the course, please visit the course website and look for the enrollment section. You'll typically need to create an account or log in if you already have one. Then, follow the steps to register for the course you are interested in. If you have any issues, you can contact the course administration for further assistance.\",\n",
       " 'source': 'OWN_KNOWLEDGE'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test our agentic RAG function\n",
    "\n",
    "agentic_rag_v1('how do I join the course?')\n",
    "# 'action': 'SEARCH', 'reasoning': 'The context is empty...\n",
    "\n",
    "# 'action': 'ANSWER'\n",
    "# 'source': 'OWN_KNOWLEDGE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b01c8ed2-2b6e-416d-93b7-511a3b2e8d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'ANSWER', 'answer': 'To patch KDE under FreeBSD, you typically follow these steps: 1. Ensure you have the necessary tools installed, such as `patch`, `make`, and `git`. 2. Download the KDE source code you want to patch. You can find it in the FreeBSD ports collection or from the KDE repositories. 3. Obtain the patch file you want to apply. This could be a patch provided by a bug report, or one you have created yourself. 4. Navigate to the directory where the KDE source code is located. 5. Apply the patch using the command: `patch < /path/to/your/patchfile.patch`. 6. After applying the patch, compile and install the updated KDE software using the usual `make install` procedure. Make sure to test the updated version to ensure your patch works as intended.', 'source': 'OWN_KNOWLEDGE'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': 'To patch KDE under FreeBSD, you typically follow these steps: 1. Ensure you have the necessary tools installed, such as `patch`, `make`, and `git`. 2. Download the KDE source code you want to patch. You can find it in the FreeBSD ports collection or from the KDE repositories. 3. Obtain the patch file you want to apply. This could be a patch provided by a bug report, or one you have created yourself. 4. Navigate to the directory where the KDE source code is located. 5. Apply the patch using the command: `patch < /path/to/your/patchfile.patch`. 6. After applying the patch, compile and install the updated KDE software using the usual `make install` procedure. Make sure to test the updated version to ensure your patch works as intended.',\n",
       " 'source': 'OWN_KNOWLEDGE'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentic_rag_v1('how patch KDE under FreeBSD?')\n",
    "# 'reasoning': 'The student is asking for a specific method to patch KDE under FreeBSD, and the context is currently empty...\n",
    "\n",
    "# 'action': 'ANSWER'\n",
    "# 'source': 'OWN_KNOWLEDGE'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff3a7ab-7e06-4d0c-8245-231be569e9a9",
   "metadata": {},
   "source": [
    "## STEP 6 - Agentic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3841e63-0c3d-49c1-b634-7a3aba2ac9ab",
   "metadata": {},
   "source": [
    "Part 2: Agentic search\n",
    "\n",
    "So far we had two actions only: search and answer.\n",
    "\n",
    "But we can let our \"agent\" formulate one or more search queries - and do it for a few iterations until we found an answer\n",
    "\n",
    "Let's build a prompt:\n",
    "\n",
    "List available actions:\n",
    "\n",
    "Search in FAQ\n",
    "\n",
    "-- Answer using own knowledge\n",
    "\n",
    "-- Answer using information extracted from FAQ\n",
    "\n",
    "-- Provide access to the previous actions\n",
    "\n",
    "Have clear stop criteria (no more than X iterations)\n",
    "\n",
    "We also specify the output format, so it's easier to parse it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acbb494e-f04c-481c-ac2d-bc946050b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deduplication function\n",
    "\n",
    "def dedup(seq):\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for el in seq:\n",
    "        _id = el['_id']\n",
    "        if _id in seen:\n",
    "            continue\n",
    "        seen.add(_id)\n",
    "        result.append(el)\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20a715a8-07c9-405c-b4d1-371510a09e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "\n",
    "The CONTEXT is build with the documents from our FAQ database.\n",
    "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
    "from FAQ to and add them to the context.\n",
    "PREVIOUS_ACTIONS contains the actions you already performed.\n",
    "\n",
    "At the beginning the CONTEXT is empty.\n",
    "\n",
    "You can perform the following actions:\n",
    "\n",
    "- Search in the FAQ database to get more data for the CONTEXT\n",
    "- Answer the question using the CONTEXT\n",
    "- Answer the question using your own knowledge\n",
    "\n",
    "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
    "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
    "\n",
    "Don't use search queries used at the previous iterations.\n",
    "\n",
    "Don't repeat previously performed actions.\n",
    "\n",
    "Don't perform more than {max_iterations} iterations for a given student question.\n",
    "The current iteration number: {iteration_number}. If we exceed the allowed number \n",
    "of iterations, give the best possible answer with the provided information.\n",
    "\n",
    "Output templates:\n",
    "\n",
    "If you want to perform search, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\",\n",
    "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER_CONTEXT\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<SEARCH_QUERIES>\n",
    "{search_queries}\n",
    "</SEARCH_QUERIES>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "<PREVIOUS_ACTIONS>\n",
    "{previous_actions}\n",
    "</PREVIOUS_ACTIONS>\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0b3478b-3a30-4c24-99f1-588368f33182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repetitive task - search, update context and search again if needed + delete duplicate results\n",
    "\n",
    "question = 'how do I do well on module 1'\n",
    "max_iterations = 3\n",
    "iteration_number = 0\n",
    "search_queries = []\n",
    "search_results  = []\n",
    "previous_actions = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e463cfa-2b6d-4259-a5ee-f48d8e97665f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 0. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I do well on module 1\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n"
     ]
    }
   ],
   "source": [
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=max_iterations,\n",
    "    iteration_number=iteration_number\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a93ee516-d289-4869-b6d2-8d84dc6e4579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n\"action\": \"SEARCH\",\\n\"reasoning\": \"The question asks for guidance on how to perform well in a specific module. I need to find tips or guidelines related to success in Module 1 from the FAQ database.\",\\n\"keywords\": [\"how to succeed in Module 1\", \"tips for Module 1\", \"Module 1 study strategy\"]\\n}'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_json = llm(prompt)\n",
    "answer_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e5c688b-4670-4674-a10e-bd0a75e305e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 'SEARCH',\n",
       " 'reasoning': 'The question asks for guidance on how to perform well in a specific module. I need to find tips or guidelines related to success in Module 1 from the FAQ database.',\n",
       " 'keywords': ['how to succeed in Module 1',\n",
       "  'tips for Module 1',\n",
       "  'Module 1 study strategy']}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = json.loads(answer_json)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c1f14b8-9df2-455e-b279-06d2aa186aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how to succeed in Module 1', 'tips for Module 1', 'Module 1 study strategy']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_actions.append(answer)\n",
    "keywords = answer['keywords']\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee55f140-1237-4ac8-9e7d-ddbcbc2de2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have to search each keyword and add results to a context\n",
    "\n",
    "for kw in keywords:\n",
    "    search_queries.append(kw)\n",
    "    sr = search(kw)\n",
    "    search_results.extend(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42fa5520-8ac5-4717-8c38-4e6c218adb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=‚Äù${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}‚Äù\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\\nAdditionally, you can check for the version of ‚Äòpy4j‚Äô of the spark you‚Äôre using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.',\n",
       "  'section': 'Module 5: pyspark',\n",
       "  'question': \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 323},\n",
       " {'text': \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\",\n",
       "  'section': 'Module 4: analytics engineering with dbt',\n",
       "  'question': \"DBT - Error: No module named 'pytz' while setting up dbt with docker\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 299},\n",
       " {'text': 'Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\\nKrishna Anand',\n",
       "  'section': 'Module 5: pyspark',\n",
       "  'question': 'Module Not Found Error in Jupyter Notebook .',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 322},\n",
       " {'text': \"Issue:\\ne‚Ä¶\\nSolution:\\npip install psycopg2-binary\\nIf you already have it, you might need to update it:\\npip install psycopg2-binary --upgrade\\nOther methods, if the above fails:\\nif you are getting the ‚Äú ModuleNotFoundError: No module named 'psycopg2' ‚Äú error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\nFirst uninstall the psycopg package\\nThen update conda or pip\\nThen install psycopg again using pip.\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\",\n",
       "  'section': 'Module 1: Docker and Terraform',\n",
       "  'question': \"Postgres - ModuleNotFoundError: No module named 'psycopg2'\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 112},\n",
       " {'text': 'create_engine(\\'postgresql://root:root@localhost:5432/ny_taxi\\')  I get the error \"TypeError: \\'module\\' object is not callable\"\\nSolution:\\nconn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\\nengine = create_engine(conn_string)',\n",
       "  'section': 'Module 1: Docker and Terraform',\n",
       "  'question': \"Python - SQLALchemy - TypeError 'module' object is not callable\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 124},\n",
       " {'text': \"Error raised during the jupyter notebook‚Äôs cell execution:\\nengine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\\nSolution: Need to install Python module ‚Äúpsycopg2‚Äù. Can be installed by Conda or pip.\",\n",
       "  'section': 'Module 1: Docker and Terraform',\n",
       "  'question': \"Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 125}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see what we found\n",
    "\n",
    "search_results = dedup(search_results)\n",
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6026702-4a47-43c1-a90a-3bc38e7438d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_number = 2\n",
    "\n",
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=max_iterations,\n",
    "    iteration_number=iteration_number\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "36622fa1-aacf-4f4a-8ff7-2ef3a817a418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'SEARCH', 'reasoning': 'The previous search did not yield relevant information for succeeding in Module 1, Docker and Terraform. I need to explore different queries that specifically target strategies and tips for success in this module.', 'keywords': ['success tips Module 1 Docker Terraform', 'study strategies Module 1', 'best practices Module 1 Docker Terraform']}\n"
     ]
    }
   ],
   "source": [
    "answer_json = llm(prompt)\n",
    "answer = json.loads(answer_json)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "141d51c4-98ad-4238-8988-1d127880c5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION #0...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 0. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"To provide a comprehensive answer, I need to gather specific tips and requirements outlined for success in Module 1 from the FAQ database.\",\n",
      "  \"keywords\": [\n",
      "    \"success in module 1\",\n",
      "    \"tips for module 1\",\n",
      "    \"requirements for module 1\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #1...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 1. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "tips for module 1\n",
      "requirements for module 1\n",
      "success in module 1\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=‚Äù${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}‚Äù\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‚Äòpy4j‚Äô of the spark you‚Äôre using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e‚Ä¶\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the ‚Äú ModuleNotFoundError: No module named 'psycopg2' ‚Äú error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook‚Äôs cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module ‚Äúpsycopg2‚Äù. Can be installed by Conda or pip.\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Module ‚Äúkafka‚Äù not found when trying to run producer.py\n",
      "answer: Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\n",
      "To create a virtual env and install packages (run only once)\n",
      "python -m venv env\n",
      "source env/bin/activate\n",
      "pip install -r ../requirements.txt\n",
      "To activate it (you'll need to run it every time you need the virtual env):\n",
      "source env/bin/activate\n",
      "To deactivate it:\n",
      "deactivate\n",
      "This works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\n",
      "Also the virtual environment should be created only to run the python file. Docker images should first all be up and running.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To provide a comprehensive answer, I need to gather specific tips and requirements outlined for success in Module 1 from the FAQ database.\", \"keywords\": [\"success in module 1\", \"tips for module 1\", \"requirements for module 1\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"Since I still haven't gathered specific tips or strategies relevant to Module 1 that can help ensure a student's success, I will explore the FAQ database further to find relevant advice or guidelines specifically targeted to this module.\",\n",
      "  \"keywords\": [\n",
      "    \"successful strategies for module 1\",\n",
      "    \"advice for excelling in module 1\",\n",
      "    \"module 1 recommendations\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #2...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 2. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "tips for module 1\n",
      "advice for excelling in module 1\n",
      "requirements for module 1\n",
      "successful strategies for module 1\n",
      "module 1 recommendations\n",
      "success in module 1\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=‚Äù${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}‚Äù\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‚Äòpy4j‚Äô of the spark you‚Äôre using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e‚Ä¶\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the ‚Äú ModuleNotFoundError: No module named 'psycopg2' ‚Äú error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook‚Äôs cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module ‚Äúpsycopg2‚Äù. Can be installed by Conda or pip.\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Module ‚Äúkafka‚Äù not found when trying to run producer.py\n",
      "answer: Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\n",
      "To create a virtual env and install packages (run only once)\n",
      "python -m venv env\n",
      "source env/bin/activate\n",
      "pip install -r ../requirements.txt\n",
      "To activate it (you'll need to run it every time you need the virtual env):\n",
      "source env/bin/activate\n",
      "To deactivate it:\n",
      "deactivate\n",
      "This works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\n",
      "Also the virtual environment should be created only to run the python file. Docker images should first all be up and running.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To provide a comprehensive answer, I need to gather specific tips and requirements outlined for success in Module 1 from the FAQ database.\", \"keywords\": [\"success in module 1\", \"tips for module 1\", \"requirements for module 1\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"Since I still haven't gathered specific tips or strategies relevant to Module 1 that can help ensure a student's success, I will explore the FAQ database further to find relevant advice or guidelines specifically targeted to this module.\", \"keywords\": [\"successful strategies for module 1\", \"advice for excelling in module 1\", \"module 1 recommendations\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"I still need to find specific guidelines or recommendations that focus on what students should do to be successful in Module 1, engaging with additional terminology that might provide deeper insights on required practices for this module.\",\n",
      "  \"keywords\": [\n",
      "    \"module 1 study tips\",\n",
      "    \"module 1 success strategies\",\n",
      "    \"best practices for module 1\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #3...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 3. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "tips for module 1\n",
      "advice for excelling in module 1\n",
      "successful strategies for module 1\n",
      "module 1 success strategies\n",
      "module 1 study tips\n",
      "best practices for module 1\n",
      "requirements for module 1\n",
      "module 1 recommendations\n",
      "success in module 1\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=‚Äù${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}‚Äù\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‚Äòpy4j‚Äô of the spark you‚Äôre using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e‚Ä¶\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the ‚Äú ModuleNotFoundError: No module named 'psycopg2' ‚Äú error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook‚Äôs cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module ‚Äúpsycopg2‚Äù. Can be installed by Conda or pip.\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Module ‚Äúkafka‚Äù not found when trying to run producer.py\n",
      "answer: Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\n",
      "To create a virtual env and install packages (run only once)\n",
      "python -m venv env\n",
      "source env/bin/activate\n",
      "pip install -r ../requirements.txt\n",
      "To activate it (you'll need to run it every time you need the virtual env):\n",
      "source env/bin/activate\n",
      "To deactivate it:\n",
      "deactivate\n",
      "This works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\n",
      "Also the virtual environment should be created only to run the python file. Docker images should first all be up and running.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Docker - cs to store all code in your default Linux distro to get the best out of file system performance (since Docker runs on WSL2 backend by default for Windows 10 Home / Windows 11 Home users).\n",
      "answer: More info in the Docker Docs on Best Practises\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To provide a comprehensive answer, I need to gather specific tips and requirements outlined for success in Module 1 from the FAQ database.\", \"keywords\": [\"success in module 1\", \"tips for module 1\", \"requirements for module 1\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"Since I still haven't gathered specific tips or strategies relevant to Module 1 that can help ensure a student's success, I will explore the FAQ database further to find relevant advice or guidelines specifically targeted to this module.\", \"keywords\": [\"successful strategies for module 1\", \"advice for excelling in module 1\", \"module 1 recommendations\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"I still need to find specific guidelines or recommendations that focus on what students should do to be successful in Module 1, engaging with additional terminology that might provide deeper insights on required practices for this module.\", \"keywords\": [\"module 1 study tips\", \"module 1 success strategies\", \"best practices for module 1\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"ANSWER\",\n",
      "  \"answer\": \"To be successful in Module 1 (Docker and Terraform), it\\u2019s essential to grasp the foundational concepts of both tools. Here are some tips:\\n\\n1. **Understanding Docker**: Familiarize yourself with Docker's architecture, including concepts like images, containers, and Dockerfiles. Practice building and running your own Docker containers.\\n\\n2. **Terraform Basics**: Learn how Terraform works, including how to write and apply configuration files. Explore its resource management capabilities for infrastructure as code.\\n\\n3. **Hands-on Practice**: Implement small projects using Docker and Terraform, such as containerizing a simple application and defining cloud resources to deploy it.\\n\\n4. **Error Resolution**: Be prepared to troubleshoot common issues. For example, dealing with module errors (like psycopg2) often involves correcting dependencies through pip or conda.\\n\\n5. **Engage with the Community**: Utilize forums, study groups, or Q&A platforms to ask questions and share knowledge with peers.\\n\\n6. **Follow Best Practices**: Adhere to best practices when writing Dockerfiles and Terraform configurations to ensure optimal performance and maintainability.\\n\\nStay diligent in your studies and seek additional resources or documentation as needed to reinforce your understanding. Good luck!\",\n",
      "  \"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# now lets create a function which will perform a search in a loop\n",
    "\n",
    "question = \"what do I need to do to be successful at module 1?\"\n",
    "\n",
    "search_queries = []\n",
    "search_results = []\n",
    "previous_actions = []\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "while True:\n",
    "    print(f'ITERATION #{iteration}...')\n",
    "\n",
    "    context = build_context(search_results)\n",
    "    prompt = prompt_template.format(\n",
    "        question=question,\n",
    "        context=context,\n",
    "        search_queries=\"\\n\".join(search_queries),\n",
    "        previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "        max_iterations=3,\n",
    "        iteration_number=iteration\n",
    "    )\n",
    "\n",
    "    print(prompt)\n",
    "\n",
    "    answer_json = llm(prompt)\n",
    "    answer = json.loads(answer_json)\n",
    "    print(json.dumps(answer, indent=2))\n",
    "\n",
    "    previous_actions.append(answer)\n",
    "\n",
    "    action = answer['action']\n",
    "    if action != 'SEARCH':\n",
    "        break\n",
    "\n",
    "    keywords = answer['keywords']\n",
    "    search_queries = list(set(search_queries) | set(keywords))\n",
    "    \n",
    "    for k in keywords:\n",
    "        res = search(k)\n",
    "        search_results.extend(res)\n",
    "\n",
    "    search_results = dedup(search_results)\n",
    "    \n",
    "    iteration = iteration + 1\n",
    "    if iteration >= 4:\n",
    "        break\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b370b760-00b6-4a9f-a871-6b2534e796a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be successful in Module 1 (Docker and Terraform), it‚Äôs essential to grasp the foundational concepts of both tools. Here are some tips:\n",
      "\n",
      "1. **Understanding Docker**: Familiarize yourself with Docker's architecture, including concepts like images, containers, and Dockerfiles. Practice building and running your own Docker containers.\n",
      "\n",
      "2. **Terraform Basics**: Learn how Terraform works, including how to write and apply configuration files. Explore its resource management capabilities for infrastructure as code.\n",
      "\n",
      "3. **Hands-on Practice**: Implement small projects using Docker and Terraform, such as containerizing a simple application and defining cloud resources to deploy it.\n",
      "\n",
      "4. **Error Resolution**: Be prepared to troubleshoot common issues. For example, dealing with module errors (like psycopg2) often involves correcting dependencies through pip or conda.\n",
      "\n",
      "5. **Engage with the Community**: Utilize forums, study groups, or Q&A platforms to ask questions and share knowledge with peers.\n",
      "\n",
      "6. **Follow Best Practices**: Adhere to best practices when writing Dockerfiles and Terraform configurations to ensure optimal performance and maintainability.\n",
      "\n",
      "Stay diligent in your studies and seek additional resources or documentation as needed to reinforce your understanding. Good luck!\n"
     ]
    }
   ],
   "source": [
    "print(answer['answer']) # for better look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62c2b829-d498-4755-bfda-321fbeffc9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6371ca73-3c02-48cb-8717-9222c2e09465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put together agentic search as a function\n",
    "\n",
    "def agentic_search(question):\n",
    "    search_queries = []\n",
    "    search_results = []\n",
    "    previous_actions = []\n",
    "\n",
    "    iteration = 0\n",
    "    \n",
    "    while True:\n",
    "        print(f'ITERATION #{iteration}...')\n",
    "    \n",
    "        context = build_context(search_results)\n",
    "        prompt = prompt_template.format(\n",
    "            question=question,\n",
    "            context=context,\n",
    "            search_queries=\"\\n\".join(search_queries),\n",
    "            previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "            max_iterations=3,\n",
    "            iteration_number=iteration\n",
    "        )\n",
    "    \n",
    "        print(prompt)\n",
    "    \n",
    "        answer_json = llm(prompt)\n",
    "        answer = json.loads(answer_json)\n",
    "        print(json.dumps(answer, indent=2))\n",
    "\n",
    "        previous_actions.append(answer)\n",
    "    \n",
    "        action = answer['action']\n",
    "        if action != 'SEARCH':\n",
    "            break\n",
    "    \n",
    "        keywords = answer['keywords']\n",
    "        search_queries = list(set(search_queries) | set(keywords))\n",
    "\n",
    "        for k in keywords:\n",
    "            res = search(k)\n",
    "            search_results.extend(res)\n",
    "    \n",
    "        search_results = dedup(search_results)\n",
    "        \n",
    "        iteration = iteration + 1\n",
    "        if iteration >= 4:\n",
    "            break\n",
    "    \n",
    "        print()\n",
    "\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "10863975-d00a-417b-afd1-a980c0dbb66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION #0...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 0. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I prepare for the course?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"The question is about how to prepare for the course, which may include study tips, course requirements, or resources that could be useful. I need to find information that specifically addresses preparation methods for the course.\",\n",
      "  \"keywords\": [\n",
      "    \"course preparation\",\n",
      "    \"how to prepare for classes\",\n",
      "    \"study tips for courses\",\n",
      "    \"course requirements\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #1...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 1. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I prepare for the course?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "course requirements\n",
      "study tips for courses\n",
      "how to prepare for classes\n",
      "course preparation\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  ‚ÄúOffice Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don‚Äôt forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a ‚Äúlive‚Äù cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Is it possible to use tool ‚ÄúX‚Äù instead of the one tool you use in the course?\n",
      "answer: Yes, this applies if you want to use Airflow or Prefect instead of Mage, AWS or Snowflake instead of GCP products or Tableau instead of Metabase or Google data studio.\n",
      "The course covers 2 alternative data stacks, one using GCP and one using local installation of everything. You can use one of them or use your tool of choice.\n",
      "Should you consider it instead of the one tool you use? That we can‚Äôt support you if you choose to use a different stack, also you would need to explain the different choices of tool for the peer review of your capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors‚Äô code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Spark Cloud Storage connector\n",
      "answer: Link to Slack Thread : has anyone figured out how to read from GCP data lake instead of downloading all the taxi data again?\n",
      "There‚Äôs a few extra steps to go into reading from GCS with PySpark\n",
      "1.)  IMPORTANT: Download the Cloud Storage connector for Hadoop here: https://cloud.google.com/dataproc/docs/concepts/connectors/cloud-storage#clusters\n",
      "As the name implies, this .jar file is what essentially connects PySpark with your GCS\n",
      "2.) Move the .jar file to your Spark file directory. I installed Spark using homebrew on my MacOS machine and I had to create a /jars directory under \"/opt/homebrew/Cellar/apache-spark/3.2.1/ (where my spark dir is located)\n",
      "3.) In your Python script, there are a few extra classes you‚Äôll have to import:\n",
      "import pyspark\n",
      "from pyspark.sql import SparkSession\n",
      "from pyspark.conf import SparkConf\n",
      "from pyspark.context import SparkContext\n",
      "4.) You must set up your configurations before building your SparkSession. Here‚Äôs my code snippet:\n",
      "conf = SparkConf() \\\n",
      ".setMaster('local[*]') \\\n",
      ".setAppName('test') \\\n",
      ".set(\"spark.jars\", \"/opt/homebrew/Cellar/apache-spark/3.2.1/jars/gcs-connector-hadoop3-latest.jar\") \\\n",
      ".set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
      ".set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", \"path/to/google_credentials.json\")\n",
      "sc = SparkContext(conf=conf)\n",
      "sc._jsc.hadoopConfiguration().set(\"fs.AbstractFileSystem.gs.impl\",  \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
      "sc._jsc.hadoopConfiguration().set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
      "sc._jsc.hadoopConfiguration().set(\"fs.gs.auth.service.account.json.keyfile\", \"path/to/google_credentials.json\")\n",
      "sc._jsc.hadoopConfiguration().set(\"fs.gs.auth.service.account.enable\", \"true\")\n",
      "5.) Once you run that, build your SparkSession with the new parameters we‚Äôd just instantiated in the previous step:\n",
      "spark = SparkSession.builder \\\n",
      ".config(conf=sc.getConf()) \\\n",
      ".getOrCreate()\n",
      "6.) Finally, you‚Äôre able to read your files straight from GCS!\n",
      "df_green = spark.read.parquet(\"gs://{BUCKET}/green/202*/\")\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Java Kafka: Tests are not picked up in VSCode\n",
      "answer: Situation: in VS Code, usually there will be a triangle icon next to each test. I couldn‚Äôt see it at first and had to do some fixes.\n",
      "Solution:\n",
      "(Source)\n",
      "VS Code\n",
      "‚Üí Explorer (first icon on the left navigation bar)\n",
      "‚Üí JAVA PROJECTS (bottom collapsable)\n",
      "‚Üí  icon next in the rightmost position to JAVA PROJECTS\n",
      "‚Üí  clean Workspace\n",
      "‚Üí Confirm by clicking Reload and Delete\n",
      "Now you will be able to see the triangle icon next to each test like what you normally see in python tests.\n",
      "E.g.:\n",
      "You can also add classes and packages in this window instead of creating files in the project directory\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Hadoop - Exception in thread \"main\" java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z\n",
      "answer: If you are seeing this (or similar) error when attempting to write to parquet, it is likely an issue with your path variables.\n",
      "For Windows, create a new User Variable ‚ÄúHADOOP_HOME‚Äù that points to your Hadoop directory. Then add ‚Äú%HADOOP_HOME%\\bin‚Äù to the PATH variable.\n",
      "Additional tips can be found here: https://stackoverflow.com/questions/41851066/exception-in-thread-main-java-lang-unsatisfiedlinkerror-org-apache-hadoop-io\n",
      "\n",
      "section: Module 3: Data Warehousing\n",
      "question: GCS Bucket - I query my dataset and get a Bad character (ASCII 0) error?\n",
      "answer: Check the Schema\n",
      "You might have a wrong formatting\n",
      "Try to upload the CSV.GZ files without formatting or going through pandas via wget\n",
      "See this Slack conversation for helpful tips\n",
      "\n",
      "section: General course-related questions\n",
      "question: Leaderboard - I am not on the leaderboard / how do I know which one I am on the leaderboard?\n",
      "answer: When you set up your account you are automatically assigned a random name such as ‚ÄúLucid Elbakyan‚Äù for example. If you want to see what your Display name is.\n",
      "Go to the Homework submission link ‚Üí  https://courses.datatalks.club/de-zoomcamp-2024/homework/hw2 - Log in > Click on ‚ÄòData Engineering Zoom Camp 2024‚Äô > click on ‚ÄòEdit Course Profile‚Äô - your display name is here, you can also change it should you wish:\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - how many Zoomcamps in a year?\n",
      "answer: There are 3 Zoom Camps in a year, as of 2024. However, they are for separate courses:\n",
      "Data-Engineering (Jan - Apr)\n",
      "MLOps (May - Aug)\n",
      "Machine Learning (Sep - Jan)\n",
      "There's only one Data-Engineering Zoomcamp ‚Äúlive‚Äù cohort per year, for the certification. Same as for the other Zoomcamps.\n",
      "They follow pretty much the same schedule for each cohort per zoomcamp. For Data-Engineering it is (generally) from Jan-Apr of the year. If you‚Äôre not interested in the Certificate, you can take any zoom camps at any time, at your own pace, out of sync with any ‚Äúlive‚Äù cohort.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - What can I do before the course starts?\n",
      "answer: You can start by installing and setting up all the dependencies and requirements:\n",
      "Google cloud account\n",
      "Google Cloud SDK\n",
      "Python 3 (installed with Anaconda)\n",
      "Terraform\n",
      "Git\n",
      "Look over the prerequisites and syllabus to see if you are comfortable with these subjects.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The question is about how to prepare for the course, which may include study tips, course requirements, or resources that could be useful. I need to find information that specifically addresses preparation methods for the course.\", \"keywords\": [\"course preparation\", \"how to prepare for classes\", \"study tips for courses\", \"course requirements\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"ANSWER_CONTEXT\",\n",
      "  \"answer\": \"To prepare for the course, you can start by installing and setting up all necessary dependencies and requirements. These include a Google Cloud account, Google Cloud SDK, Python 3 (installed with Anaconda), Terraform, and Git. Additionally, reviewing the prerequisites and syllabus will help ensure you are comfortable with the subjects covered in the course. It's also a good idea to familiarize yourself with the course materials and assignments to get a head start.\",\n",
      "  \"source\": \"CONTEXT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# and test our agentic search function\n",
    "\n",
    "answer = agentic_search('how do I prepare for the course?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eefe355a-e1eb-473c-a94e-de6f191bc4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'ANSWER_CONTEXT', 'answer': \"To prepare for the course, you can start by installing and setting up all necessary dependencies and requirements. These include a Google Cloud account, Google Cloud SDK, Python 3 (installed with Anaconda), Terraform, and Git. Additionally, reviewing the prerequisites and syllabus will help ensure you are comfortable with the subjects covered in the course. It's also a good idea to familiarize yourself with the course materials and assignments to get a head start.\", 'source': 'CONTEXT'}\n"
     ]
    }
   ],
   "source": [
    "# for better formatting\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c5dff8c5-7f8d-48b2-978e-98cb00be9a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To prepare for the course, you can start by installing and setting up all necessary dependencies and requirements. These include a Google Cloud account, Google Cloud SDK, Python 3 (installed with Anaconda), Terraform, and Git. Additionally, reviewing the prerequisites and syllabus will help ensure you are comfortable with the subjects covered in the course. It's also a good idea to familiarize yourself with the course materials and assignments to get a head start.\n"
     ]
    }
   ],
   "source": [
    "# no need of parsing json?\n",
    "# answer = json.loads(answer)\n",
    "\n",
    "print(answer['answer'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b7da6d-c060-41ac-ac61-f53c6bcccef9",
   "metadata": {},
   "source": [
    "## STEP 7 - Function calling (\"tool use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8876c3d7-f38e-48ab-adf0-5d6307001090",
   "metadata": {},
   "source": [
    "Part 3: Function calling - code from\n",
    "https://github.com/alexeygrigorev/rag-agents-workshop/tree/main\n",
    "\n",
    "Function calling in OpenAI\n",
    "\n",
    "We put all this logic inside our prompt.\n",
    "\n",
    "But OpenAI and other providers provide a convenient API for adding extra functionality like search.\n",
    "\n",
    "https://platform.openai.com/docs/guides/function-calling\n",
    "\n",
    "It's called \"function calling\" - you define functions that the model can call, and if it decides to make a call, it returns structured output for that.\n",
    "\n",
    "For example, let's take our search function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a38727b-9713-453f-a5da-5cd071fef0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search tool\n",
    "\n",
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a953f43-55fc-4aa3-9ea4-747b9c7e2325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': \"Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\\nTo create a virtual env and install packages (run only once)\\npython -m venv env\\nsource env/bin/activate\\npip install -r ../requirements.txt\\nTo activate it (you'll need to run it every time you need the virtual env):\\nsource env/bin/activate\\nTo deactivate it:\\ndeactivate\\nThis works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\\nAlso the virtual environment should be created only to run the python file. Docker images should first all be up and running.\", 'section': 'Module 6: streaming with kafka', 'question': 'Module ‚Äúkafka‚Äù not found when trying to run producer.py', 'course': 'data-engineering-zoomcamp', '_id': 372}, {'text': \"Below I have listed some steps I took to rectify this and potentially other minor errors, in Windows:\\nUse the git bash terminal in windows.\\nActivate python venv from git bash: source .venv/Scripts/activate\\nModify the seed_kafka.py file: in the first line, replace python3 with python.\\nNow from git bash, run the seed-kafka cmd. It should work now.\\nAdditional Notes:\\nYou can connect to the RisingWave cluster from Powershell with the command psql -h localhost -p 4566 -d dev -U root , otherwise it asks for a password.\\nThe equivalent of source commands.sh  in Powershell is . .\\\\commands.sh from the workshop directory.\\nHope this can save you from some trouble in case you're doing this workshop on Windows like I am.\\n‚Äî--------------------------------------------------------------------------------------\", 'section': 'Workshop 2 - RisingWave', 'question': 'Psycopg2 InternalError: Failed to run the query - when running the seed-kafka command after initial setup.', 'course': 'data-engineering-zoomcamp', '_id': 425}, {'text': 'In the project directory, run:\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java', 'section': 'Module 6: streaming with kafka', 'question': 'Java Kafka: How to run producer/consumer/kstreams/etc in terminal', 'course': 'data-engineering-zoomcamp', '_id': 389}, {'text': 'If you have this error, it most likely that your kafka broker docker container is not working.\\nUse docker ps to confirm\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.', 'section': 'Module 6: streaming with kafka', 'question': 'kafka.errors.NoBrokersAvailable: NoBrokersAvailable', 'course': 'data-engineering-zoomcamp', '_id': 379}, {'text': 'In my set up, all of the dependencies listed in gradle.build were not installed in <project_name>-1.0-SNAPSHOT.jar.\\nSolution:\\nIn build.gradle file, I added the following at the end:\\nshadowJar {\\narchiveBaseName = \"java-kafka-rides\"\\narchiveClassifier = \\'\\'\\n}\\nAnd then in the command line ran ‚Äògradle shadowjar‚Äô, and run the script from java-kafka-rides-1.0-SNAPSHOT.jar created by the shadowjar', 'section': 'Module 6: streaming with kafka', 'question': 'Java Kafka: <project_name>-1.0-SNAPSHOT.jar errors: package xxx does not exist even after gradle build', 'course': 'data-engineering-zoomcamp', '_id': 387}]\n"
     ]
    }
   ],
   "source": [
    "answer = search(\"How to run Kafka in Docker\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4868ba76-c685-4003-bfa5-6ac3207940d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to describe our search function for OpenAI / Pydantic:\n",
    "# (this is a json wrapper to use our minsearch function = search tool from above ))\n",
    "\n",
    "search_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"search\",\n",
    "    \"description\": \"Search the FAQ database\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Search query text to look up in the course FAQ.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "# \"name\": \"search\" - based on this Python will call search(query) from above\n",
    "# and pass a property \"query\": { \"type\": \"string\" ... when / into this function call object is created?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8d97c9-d74f-4c07-b0dc-57b081370ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

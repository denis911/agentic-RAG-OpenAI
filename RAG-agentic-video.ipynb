{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff344490-394e-479f-bc97-17882476d056",
   "metadata": {},
   "source": [
    "## STEP 0 - install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9206afd3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# source is https://www.youtube.com/watch?v=GH3lrOsU3AU\n",
    "# and notebook is https://github.com/DataTalksClub/llm-zoomcamp/blob/main/0a-agents/notebook.ipynb\n",
    "# Follow along this tutorial: https://github.com/alexeygrigorev/rag-agents-workshop\n",
    "\n",
    "# STEP 0 - installing packages we need here and in the VS code terminal:\n",
    "\n",
    "# Run in VS code terminal:\n",
    "# pip install --upgrade pip # no reminders after!\n",
    "# pip install tqdm notebook==7.1.2 openai elasticsearch==8.13.0 pandas scikit-learn ipywidgets\n",
    "# jupyter notebook # to run jupyter engine locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4e37acb-1feb-4da5-9ab5-b35d80df1171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install minsearch -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e675499-6969-48f7-b42a-3b51a37c3516",
   "metadata": {},
   "source": [
    "## STEP 1 - download evaluation data from Github and build in-memory search index with minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d23e682f-5025-448e-9687-28e26d0fce22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Problem description\\nInfrastructure created in AWS with CD-Deploy Action needs to be destroyed\\nSolution description\\nFrom local:\\nterraform init -backend-config=\"key=mlops-zoomcamp-prod.tfstate\" --reconfigure\\nterraform destroy --var-file vars/prod.tfvars\\nAdded by Erick Calderin',\n",
       " 'section': 'Module 6: Best practices',\n",
       " 'question': 'How to destroy infrastructure created via GitHub Actions',\n",
       " 'course': 'mlops-zoomcamp'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download our FAQ dataset\n",
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "documents[-1] # to see a format of downloaded FAQ dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d7c1561-c33b-4817-9160-0d659cd8102e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x7deac329d370>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build index - takes a few seconds with minsearch\n",
    "\n",
    "from minsearch import AppendableIndex\n",
    "\n",
    "index = AppendableIndex(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9d58d90-b092-4318-9daf-5c22ed75bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a search function with weights: boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "# number of results 5 and course is hard coded here  - filter_dict={'course': 'data-engineering-zoomcamp'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee44aa1e-eb04-436a-bd70-c944c625b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Can I still join the course?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "526dec30-411e-4965-8c95-8fa2f136cb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I still join the course after the start date?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 2},\n",
       " {'text': \"No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Certificate - Can I follow the course in a self-paced mode and get a certificate?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 11},\n",
       " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 7},\n",
       " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 0},\n",
       " {'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 3}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if our search function works \n",
    "\n",
    "search(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53aa958-7f3d-4366-a8d8-77f5eeb644e1",
   "metadata": {},
   "source": [
    "## STEP 2 - build prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10a7ef93-818e-4e91-9f57-52b34c7c6e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a prompt\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2c19daf-7c13-4a5e-a202-e92fe9871560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
      "Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "\n",
      "<QUESTION>\n",
      "Can I still join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT>\n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?\n",
      "answer: You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\n",
      "\n",
      "\n",
      "</CONTEXT>\n"
     ]
    }
   ],
   "source": [
    "# test how our prompt build works by calling search(question)\n",
    "\n",
    "prompt = build_prompt(question, search(question))\n",
    "print(prompt) # better formatted for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1437dbe4-a21b-4d5b-b38c-fcb1c2a65faa",
   "metadata": {},
   "source": [
    "## STEP 3 - Connect to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8959bb41-fe64-4a0c-a513-09193cc1ff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = search(question)\n",
    "# just repeating step 1 - keyword search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f68040dd-3e23-4a44-8d55-30f651bce87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = build_prompt(question, search_results)\n",
    "# repeating step 2 - building prompt on top of search results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3366dc0c-7a3d-4955-9b84-b4d06301c157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "🔑 Enter your OpenAI API key:  ········\n"
     ]
    }
   ],
   "source": [
    "# connecting to LLM, entering our API KEY\n",
    "import os\n",
    "from getpass import getpass\n",
    "from openai import OpenAI\n",
    "\n",
    "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
    "    openai_api_key = getpass(\"🔑 Enter your OpenAI API key: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92bf5fd8-fa18-4c07-b8c3-96eaaada704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to send our prompt to llm \n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56cbbc89-489a-439f-886e-8c83fc3e1838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you can still join the course even after the start date. You are eligible to submit homeworks, but make sure to keep track of deadlines for turning in the final projects.\n"
     ]
    }
   ],
   "source": [
    "# test if our llm can answer something meaningful based on prompt provided\n",
    "\n",
    "answer = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ada0a00b-186c-4ada-b4a8-a1b1732e81e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
      "Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "\n",
      "<QUESTION>\n",
      "Can I still join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT>\n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?\n",
      "answer: You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\n",
      "\n",
      "\n",
      "</CONTEXT>\n"
     ]
    }
   ],
   "source": [
    "print(prompt) # this is what we have sent to llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870cb933-452c-41f3-b99c-44c72bc0af59",
   "metadata": {},
   "source": [
    "## STEP 4 - assemble our RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71781bd1-7beb-4ad4-8ab8-5c15ddd7e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is our RAG pipeline\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "003417eb-7010-48af-bdbc-02da09f89fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but there is no information provided in the context regarding how to patch KDE under FreeBSD. Please refer to the official documentation or community forums related to FreeBSD and KDE for assistance.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test by irrelevant question - something which is NOT in FAQ\n",
    "\n",
    "rag(\"How do I patch KDE under FreeBSD?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1788745b-4d66-4458-9e01-238b33536efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The provided context does not contain any information regarding what Shakespeare said about peeling a carrot.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"What Shakespeare said about peeling a carrot?\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "321524b2-58ec-49a0-a6e5-0984cc69dcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To run Kafka in Docker, follow these steps:\n",
      "\n",
      "1. Navigate to the folder containing your Docker Compose YAML file.\n",
      "2. Use the command `docker compose up -d` to start all the instances, including the Kafka broker.\n",
      "3. You can check if your Kafka broker Docker container is running by using the command `docker ps`.\n",
      "\n",
      "Make sure all Docker images are up and running before you attempt to use Kafka.\n"
     ]
    }
   ],
   "source": [
    "# relevant question - it actually was in FAQ\n",
    "answer = rag(\"How to run Kafka in Docker\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37a06640-c69c-4799-b4e6-8ce236fae194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patching KDE under FreeBSD involves several steps, primarily focusing on applying updates or fixes to the KDE software components you have installed. Below are the general steps to patch KDE on a FreeBSD system:\n",
      "\n",
      "### 1. **Updating FreeBSD Ports Tree**\n",
      "\n",
      "FreeBSD uses a ports collection to manage software installations, which includes KDE. First, make sure your ports collection is up to date:\n",
      "\n",
      "```bash\n",
      "portsnap fetch update\n",
      "```\n",
      "\n",
      "If you haven't used `portsnap` before, you may need to initialize it first:\n",
      "\n",
      "```bash\n",
      "portsnap fetch extract\n",
      "```\n",
      "\n",
      "### 2. **Identifying Installed KDE Components**\n",
      "\n",
      "Determine which KDE components are installed. You can list installed ports with:\n",
      "\n",
      "```bash\n",
      "pkg info | grep kde\n",
      "```\n",
      "\n",
      "Or, if you prefer to see the specific packages installed via the ports tree:\n",
      "\n",
      "```bash\n",
      "ls /usr/ports/x11/kde5/\n",
      "```\n",
      "\n",
      "### 3. **Applying Patches**\n",
      "\n",
      "If you are aware of specific patches that need to be applied to the KDE components, you can do this with the following steps:\n",
      "\n",
      "1. **Navigate to the port directory:**\n",
      "\n",
      "   For instance, if you want to patch `kde5`, navigate to its directory:\n",
      "\n",
      "   ```bash\n",
      "   cd /usr/ports/x11/kde5/\n",
      "   ```\n",
      "\n",
      "2. **Fetch and Apply the Patch:**\n",
      "   \n",
      "   You can download the patch file and apply it manually. Place the patches in the `files` directory within the port directory.\n",
      "\n",
      "3. **Create a Custom Patch (Optional):**\n",
      "\n",
      "   If you need to create a new patch, you can do so using `diff`. For example, if you have modified a source file, you can generate a diff:\n",
      "\n",
      "   ```bash\n",
      "   diff -u original_file modified_file > /usr/ports/x11/kde5/files/my_patch.patch\n",
      "   ```\n",
      "\n",
      "   Ensure that the patch file follows the naming conventions so that it will be recognized by the ports build system.\n",
      "\n",
      "4. **Rebuild the Port:**\n",
      "\n",
      "   After applying patches, you need to rebuild the port:\n",
      "\n",
      "   ```bash\n",
      "   make clean install\n",
      "   ```\n",
      "\n",
      "### 4. **Using pkg for Binary Packages**\n",
      "\n",
      "If you prefer using binary packages rather than compiling from ports, you can update KDE by simply running:\n",
      "\n",
      "```bash\n",
      "pkg update\n",
      "pkg upgrade\n",
      "```\n",
      "\n",
      "This will fetch and install the latest versions of the installed packages, including KDE components. Note that this will only include patches or versions released by the FreeBSD maintainers.\n",
      "\n",
      "### 5. **Testing Changes**\n",
      "\n",
      "Once the update or patch application is complete, it’s a good practice to test your KDE environment to ensure everything is functioning as expected.\n",
      "\n",
      "### 6. **Keeping Track of Changes**\n",
      "\n",
      "If you are maintaining patches, consider keeping a changelog or documentation for what has been patched for future reference.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Remember that applying patches directly can lead to issues, especially when the ports tree is updated. Always ensure that your patches are still valid with the latest code. After following these steps, you should have patched KDE successfully on your FreeBSD installation.\n"
     ]
    }
   ],
   "source": [
    "# LLM by itself know the answer, but our RAG is prohibiting it\n",
    "# above rag(\"How do I patch KDE under FreeBSD?\") returned nothing, but - \n",
    "print(llm(\"How do I patch KDE under FreeBSD?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9eb3baa8-7046-4262-a63e-4b304fe0ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually this was the main idea for STEP 5 below - if llm can answer question by itself, nice!\n",
    "# if not - it should be able to search our FAQ database and build the context for answer..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f64f5c-3f07-4f42-aac4-ef1aa7b2a98b",
   "metadata": {},
   "source": [
    "## STEP 5 - \"Agentic\" RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "869f1f09-7145-49ee-a222-d173457b20ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# essentially we only modify our prompt - so llm can decide either to give an answer immediately\n",
    "# or use a SEARCH tool to get more CONTEXT from our FAQ\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "At the beginning the context is EMPTY.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "If CONTEXT is EMPTY, you can use our FAQ database.\n",
    "In this case, use the following output template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\"\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75385600-f09c-444a-8189-00d450e3321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Can I still join the course?'\n",
    "context = 'EMPTY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9642963-cdde-472e-b98b-1a134cc4b98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "Can I still join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "EMPTY\n",
      "</CONTEXT>\n",
      "\n",
      "If CONTEXT is EMPTY, you can use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(question=question, context=context)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d2c6d4e-5dfb-473c-a0c5-a655849e90db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n\"action\": \"SEARCH\",\\n\"reasoning\": \"The question about joining the course does not provide specific information regarding enrollment deadlines or late registration policies, so I need to refer to the FAQ database for accurate information.\"\\n}'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_json = llm(prompt)\n",
    "answer_json \n",
    "# model decided to use \"SEARCH\" function because CONTEXT is empty\n",
    "# and provided a reason for it  - \"reasoning\": \"I am unsure about the specific enrollment dates..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b60d4dfe-ad36-4e86-a873-43c123206642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SEARCH'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# we can parse the llm answer and use tool if appropriate:\n",
    "\n",
    "answer = json.loads(answer_json)\n",
    "answer['action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d71f231-1936-48ec-a271-e77a83823e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets ask LLM something it knows already well:\n",
    "question = 'Can I run Docker on Windows 10?'\n",
    "context = 'EMPTY'\n",
    "prompt = prompt_template.format(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f1e9aa1-c624-4c31-b23a-4796fe243aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n\"action\": \"ANSWER\",\\n\"answer\": \"Yes, you can run Docker on Windows 10. Docker provides a version called Docker Desktop, which is compatible with Windows 10 Pro, Enterprise, and Education editions. For Windows 10 Home, Docker Desktop has introduced WSL 2 (Windows Subsystem for Linux) support, allowing you to run Docker containers as well. You\\'ll need to enable WSL 2 and ensure that your system meets the necessary requirements for installation.\",\\n\"source\": \"OWN_KNOWLEDGE\"\\n}'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_json = llm(prompt)\n",
    "answer_json \n",
    "# it provides answer immediately - zero shot - action\": \"ANSWER\":\n",
    "# and says it knows it already - \"source\": \"OWN_KNOWLEDGE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c445f22-9ca0-4d4d-b5dc-84dfcaaaff42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ANSWER'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = json.loads(answer_json)\n",
    "answer['action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b107c7e-5b1d-4862-821b-edc3cb9be37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if model says SEARCH then we need to use a search tool and build context + update prompt\n",
    "\n",
    "def build_context(search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    return context.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b6c1333-832a-4378-b322-84c24611982b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "Can I still join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?\n",
      "answer: You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\n",
      "</CONTEXT>\n",
      "\n",
      "If CONTEXT is EMPTY, you can use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# asking something it should search for:\n",
    "question = 'Can I still join the course?'\n",
    "\n",
    "search_results = search(question)\n",
    "context = build_context(search_results)\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "print(prompt) # for better formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6e63838-4743-4629-b5ff-5e20e4b137ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"Yes, you can still join the course after the start date even if you haven't registered. You are eligible to submit assignments, but remember to pay attention to the deadlines for the final projects.\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# lets ask llm after we performed the search as advised and updated llm context\n",
    "\n",
    "answer_json = llm(prompt)\n",
    "print(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "653e62b3-403f-4766-a302-32b224cd7c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to put everything together and parse our response json automatically\n",
    "# algo - if \"action\": \"SEARCH\" then llm uses our FAQ search tool\n",
    "# if \"action\": \"ANSWER\" - then it answers immediately ...\n",
    "\n",
    "def agentic_rag_v1(question):\n",
    "    context = \"EMPTY\"\n",
    "    prompt = prompt_template.format(question=question, context=context)\n",
    "    answer_json = llm(prompt)\n",
    "    answer = json.loads(answer_json)\n",
    "    print(answer)\n",
    "\n",
    "    if answer['action'] == 'SEARCH':\n",
    "        print('need to perform search...')\n",
    "        search_results = search(question)\n",
    "        context = build_context(search_results)\n",
    "        \n",
    "        prompt = prompt_template.format(question=question, context=context)\n",
    "        answer_json = llm(prompt)\n",
    "        answer = json.loads(answer_json)\n",
    "        print(answer)\n",
    "\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b8617e7-653c-4f9c-a952-0e4321bfb2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'SEARCH', 'reasoning': 'The context is empty, and I need to retrieve information about how to join the course from the FAQ database.'}\n",
      "need to perform search...\n",
      "{'action': 'ANSWER', 'answer': \"To join the course, you need to register using the provided link before the course starts. Even if the course has already started, you can still participate by submitting homework, but be sure to adhere to deadlines for the final project. It's also recommended to join the course public Google Calendar and the Telegram channel for announcements.\", 'source': 'CONTEXT'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': \"To join the course, you need to register using the provided link before the course starts. Even if the course has already started, you can still participate by submitting homework, but be sure to adhere to deadlines for the final project. It's also recommended to join the course public Google Calendar and the Telegram channel for announcements.\",\n",
       " 'source': 'CONTEXT'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test our agentic RAG function\n",
    "\n",
    "agentic_rag_v1('how do I join the course?')\n",
    "# 'action': 'SEARCH', 'reasoning': 'The context is empty...\n",
    "\n",
    "# 'action': 'ANSWER'\n",
    "# 'source': 'OWN_KNOWLEDGE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b01c8ed2-2b6e-416d-93b7-511a3b2e8d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'SEARCH', 'reasoning': 'The student is asking for a specific method to patch KDE under FreeBSD, and the context is currently empty, indicating that I should look for appropriate information in the FAQ database.'}\n",
      "need to perform search...\n",
      "{'action': 'ANSWER', 'answer': \"To patch KDE under FreeBSD, you can follow these steps:\\n\\n1. **Ensure Ports Collection is Updated**: Make sure your ports collection is up to date. You can do this by running:\\n   ```\\n   portsnap fetch update\\n   ```\\n\\n2. **Navigate to the KDE Port Directory**: Go to the directory of the KDE component you wish to patch. For example, if you want to patch `kde5`, navigate to:\\n   ```\\n   cd /usr/ports/x11/kde5\\n   ```\\n\\n3. **Apply the Patch**: Create or modify a patch file in the `files` directory of that port. You can add your patch file (for example, `my_patch.diff`) in the `files` directory.\\n   ```\\n   cp /path/to/my_patch.diff files/\\n   ```  \\n   After adding the patch, run:\\n   ```\\n   make patch\\n   ```\\n   This command applies the patch.\\n\\n4. **Compile and Install**: After applying the patch, compile and install the port by running:\\n   ```\\n   make install clean\\n   ```\\n\\n5. **Verify**: Ensure that your patch has been correctly applied and that the updated version of KDE works as expected.\\n\\nAlways keep backups and test in a safe environment if you're unsure about the patching process.\", 'source': 'OWN_KNOWLEDGE'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': \"To patch KDE under FreeBSD, you can follow these steps:\\n\\n1. **Ensure Ports Collection is Updated**: Make sure your ports collection is up to date. You can do this by running:\\n   ```\\n   portsnap fetch update\\n   ```\\n\\n2. **Navigate to the KDE Port Directory**: Go to the directory of the KDE component you wish to patch. For example, if you want to patch `kde5`, navigate to:\\n   ```\\n   cd /usr/ports/x11/kde5\\n   ```\\n\\n3. **Apply the Patch**: Create or modify a patch file in the `files` directory of that port. You can add your patch file (for example, `my_patch.diff`) in the `files` directory.\\n   ```\\n   cp /path/to/my_patch.diff files/\\n   ```  \\n   After adding the patch, run:\\n   ```\\n   make patch\\n   ```\\n   This command applies the patch.\\n\\n4. **Compile and Install**: After applying the patch, compile and install the port by running:\\n   ```\\n   make install clean\\n   ```\\n\\n5. **Verify**: Ensure that your patch has been correctly applied and that the updated version of KDE works as expected.\\n\\nAlways keep backups and test in a safe environment if you're unsure about the patching process.\",\n",
       " 'source': 'OWN_KNOWLEDGE'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentic_rag_v1('how patch KDE under FreeBSD?')\n",
    "# 'reasoning': 'The student is asking for a specific method to patch KDE under FreeBSD, and the context is currently empty...\n",
    "\n",
    "# 'action': 'ANSWER'\n",
    "# 'source': 'OWN_KNOWLEDGE'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff3a7ab-7e06-4d0c-8245-231be569e9a9",
   "metadata": {},
   "source": [
    "## STEP 6 - Agentic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acbb494e-f04c-481c-ac2d-bc946050b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deduplication function\n",
    "\n",
    "def dedup(seq):\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for el in seq:\n",
    "        _id = el['_id']\n",
    "        if _id in seen:\n",
    "            continue\n",
    "        seen.add(_id)\n",
    "        result.append(el)\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20a715a8-07c9-405c-b4d1-371510a09e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "\n",
    "The CONTEXT is build with the documents from our FAQ database.\n",
    "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
    "from FAQ to and add them to the context.\n",
    "PREVIOUS_ACTIONS contains the actions you already performed.\n",
    "\n",
    "At the beginning the CONTEXT is empty.\n",
    "\n",
    "You can perform the following actions:\n",
    "\n",
    "- Search in the FAQ database to get more data for the CONTEXT\n",
    "- Answer the question using the CONTEXT\n",
    "- Answer the question using your own knowledge\n",
    "\n",
    "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
    "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
    "\n",
    "Don't use search queries used at the previous iterations.\n",
    "\n",
    "Don't repeat previously performed actions.\n",
    "\n",
    "Don't perform more than {max_iterations} iterations for a given student question.\n",
    "The current iteration number: {iteration_number}. If we exceed the allowed number \n",
    "of iterations, give the best possible answer with the provided information.\n",
    "\n",
    "Output templates:\n",
    "\n",
    "If you want to perform search, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\",\n",
    "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER_CONTEXT\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<SEARCH_QUERIES>\n",
    "{search_queries}\n",
    "</SEARCH_QUERIES>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "<PREVIOUS_ACTIONS>\n",
    "{previous_actions}\n",
    "</PREVIOUS_ACTIONS>\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0b3478b-3a30-4c24-99f1-588368f33182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repetitive task - search, update context and search again if needed + delete duplicate results\n",
    "\n",
    "question = 'how do I do well on module 1'\n",
    "max_iterations = 3\n",
    "iteration_number = 0\n",
    "search_queries = []\n",
    "search_results  = []\n",
    "previous_actions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e463cfa-2b6d-4259-a5ee-f48d8e97665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=max_iterations,\n",
    "    iteration_number=iteration_number\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a93ee516-d289-4869-b6d2-8d84dc6e4579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n\"action\": \"SEARCH\",\\n\"reasoning\": \"To provide the student with specific strategies and best practices for succeeding in Module 1, I will look for frequently asked questions or tips related to this particular module.\",\\n\"keywords\": [\"how to succeed in Module 1\", \"tips for Module 1\", \"Module 1 study strategies\"]\\n}'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_json = llm(prompt)\n",
    "answer_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e5c688b-4670-4674-a10e-bd0a75e305e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 'SEARCH',\n",
       " 'reasoning': 'To provide the student with specific strategies and best practices for succeeding in Module 1, I will look for frequently asked questions or tips related to this particular module.',\n",
       " 'keywords': ['how to succeed in Module 1',\n",
       "  'tips for Module 1',\n",
       "  'Module 1 study strategies']}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = json.loads(answer_json)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c1f14b8-9df2-455e-b279-06d2aa186aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how to succeed in Module 1',\n",
       " 'tips for Module 1',\n",
       " 'Module 1 study strategies']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_actions.append(answer)\n",
    "keywords = answer['keywords']\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee55f140-1237-4ac8-9e7d-ddbcbc2de2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have to search each keyword and add results to a context\n",
    "\n",
    "for kw in keywords:\n",
    "    search_queries.append(kw)\n",
    "    sr = search(kw)\n",
    "    search_results.extend(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42fa5520-8ac5-4717-8c38-4e6c218adb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\\nAdditionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.',\n",
       "  'section': 'Module 5: pyspark',\n",
       "  'question': \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 323},\n",
       " {'text': \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\",\n",
       "  'section': 'Module 4: analytics engineering with dbt',\n",
       "  'question': \"DBT - Error: No module named 'pytz' while setting up dbt with docker\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 299},\n",
       " {'text': 'Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\\nKrishna Anand',\n",
       "  'section': 'Module 5: pyspark',\n",
       "  'question': 'Module Not Found Error in Jupyter Notebook .',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 322},\n",
       " {'text': \"Issue:\\ne…\\nSolution:\\npip install psycopg2-binary\\nIf you already have it, you might need to update it:\\npip install psycopg2-binary --upgrade\\nOther methods, if the above fails:\\nif you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\nFirst uninstall the psycopg package\\nThen update conda or pip\\nThen install psycopg again using pip.\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\",\n",
       "  'section': 'Module 1: Docker and Terraform',\n",
       "  'question': \"Postgres - ModuleNotFoundError: No module named 'psycopg2'\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 112},\n",
       " {'text': 'create_engine(\\'postgresql://root:root@localhost:5432/ny_taxi\\')  I get the error \"TypeError: \\'module\\' object is not callable\"\\nSolution:\\nconn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\\nengine = create_engine(conn_string)',\n",
       "  'section': 'Module 1: Docker and Terraform',\n",
       "  'question': \"Python - SQLALchemy - TypeError 'module' object is not callable\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 124},\n",
       " {'text': \"Error raised during the jupyter notebook’s cell execution:\\nengine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\\nSolution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\",\n",
       "  'section': 'Module 1: Docker and Terraform',\n",
       "  'question': \"Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 125}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see what we found\n",
    "\n",
    "search_results = dedup(search_results)\n",
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6026702-4a47-43c1-a90a-3bc38e7438d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_number = 2\n",
    "\n",
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=max_iterations,\n",
    "    iteration_number=iteration_number\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36622fa1-aacf-4f4a-8ff7-2ef3a817a418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'SEARCH', 'reasoning': 'The previous search did not yield any specific strategies or guidelines for succeeding in Module 1, so I will refine my search to focus more on study tips, recommended resources, and common pitfalls related specifically to Docker and Terraform, which are the key subjects of Module 1.', 'keywords': ['Module 1 Docker study tips', 'Module 1 Terraform tips', 'best practices Module 1']}\n"
     ]
    }
   ],
   "source": [
    "answer_json = llm(prompt)\n",
    "answer = json.loads(answer_json)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "141d51c4-98ad-4238-8988-1d127880c5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION #0...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 0. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"To provide a comprehensive answer regarding success in module 1, I will search for any guidelines, tips, or resources that may be available in the FAQ database. This will help ensure that the information is relevant and accurate.\",\n",
      "  \"keywords\": [\n",
      "    \"successful tips for module 1\",\n",
      "    \"guidelines for module 1\",\n",
      "    \"resources for module 1 success\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #1...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 1. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "successful tips for module 1\n",
      "guidelines for module 1\n",
      "resources for module 1 success\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: data-engineering-zoomcamp/week_6_stream_processing/python/resources/rides.csv is missing\n",
      "answer: Copy the file found in the Java example: data-engineering-zoomcamp/week_6_stream_processing/java/kafka_examples/src/main/resources/rides.csv\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: WSL - Insufficient system resources exist to complete the requested service.\n",
      "answer: Cause:\n",
      "It happens because the apps are not updated. To be specific, search for any pending updates for Windows Terminal, WSL and Windows Security updates.\n",
      "Solution\n",
      "for updating Windows terminal which worked for me:\n",
      "Go to Microsoft Store.\n",
      "Go to the library of apps installed in your system.\n",
      "Search for Windows terminal.\n",
      "Update the app and restart your system to  see the changes.\n",
      "For updating the Windows security updates:\n",
      "Go to Windows updates and check if there are any pending updates from Windows, especially security updates.\n",
      "Do restart your system once the updates are downloaded and installed successfully.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To provide a comprehensive answer regarding success in module 1, I will search for any guidelines, tips, or resources that may be available in the FAQ database. This will help ensure that the information is relevant and accurate.\", \"keywords\": [\"successful tips for module 1\", \"guidelines for module 1\", \"resources for module 1 success\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"Since the previous search did not yield specific information about success tips for Module 1, I will search for any general strategies or recommendations that can help students excel in this module. This may include study tips, resources, or related best practices that have not yet been covered.\",\n",
      "  \"keywords\": [\n",
      "    \"success strategies for module 1\",\n",
      "    \"study tips module 1\",\n",
      "    \"resources for excelling in module 1\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #2...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 2. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "success strategies for module 1\n",
      "resources for excelling in module 1\n",
      "study tips module 1\n",
      "successful tips for module 1\n",
      "guidelines for module 1\n",
      "resources for module 1 success\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: data-engineering-zoomcamp/week_6_stream_processing/python/resources/rides.csv is missing\n",
      "answer: Copy the file found in the Java example: data-engineering-zoomcamp/week_6_stream_processing/java/kafka_examples/src/main/resources/rides.csv\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: WSL - Insufficient system resources exist to complete the requested service.\n",
      "answer: Cause:\n",
      "It happens because the apps are not updated. To be specific, search for any pending updates for Windows Terminal, WSL and Windows Security updates.\n",
      "Solution\n",
      "for updating Windows terminal which worked for me:\n",
      "Go to Microsoft Store.\n",
      "Go to the library of apps installed in your system.\n",
      "Search for Windows terminal.\n",
      "Update the app and restart your system to  see the changes.\n",
      "For updating the Windows security updates:\n",
      "Go to Windows updates and check if there are any pending updates from Windows, especially security updates.\n",
      "Do restart your system once the updates are downloaded and installed successfully.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To provide a comprehensive answer regarding success in module 1, I will search for any guidelines, tips, or resources that may be available in the FAQ database. This will help ensure that the information is relevant and accurate.\", \"keywords\": [\"successful tips for module 1\", \"guidelines for module 1\", \"resources for module 1 success\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"Since the previous search did not yield specific information about success tips for Module 1, I will search for any general strategies or recommendations that can help students excel in this module. This may include study tips, resources, or related best practices that have not yet been covered.\", \"keywords\": [\"success strategies for module 1\", \"study tips module 1\", \"resources for excelling in module 1\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"ANSWER\",\n",
      "  \"answer\": \"To be successful in Module 1, which focuses on Docker and Terraform, here are some general tips:\\n\\n1. **Familiarize Yourself with the Basics**: Ensure you have a good understanding of the basic concepts of Docker and Terraform, including how to create, manage, and deploy containers using Docker, as well as infrastructure as code with Terraform.\\n\\n2. **Hands-On Practice**: Engage with the hands-on labs and exercises provided in the module. Practical application of concepts is crucial in understanding how these tools work in real-world scenarios.\\n\\n3. **Utilize Community Resources**: Leverage forums, YouTube tutorials, and documentation. The Docker and Terraform communities are vast, and you can find plenty of resources that will enhance your understanding.\\n\\n4. **Ask for Help**: Don't hesitate to reach out to peers or instructors if you have questions or encounter difficulties. Collaboration can enhance your learning experience.\\n\\n5. **Stay Organized**: Keep your notes, configuration files, and commands organized for easy reference while working through the module.\\n\\n6. **Review and Reinforce**: Regularly review what you've learned to reinforce the concepts. Building small projects or practice environments using Docker and Terraform can help solidify your knowledge.\\n\\nBy focusing on these strategies, you can position yourself for success in Module 1.\",\n",
      "  \"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# now lets create a function which will perform a search in a loop\n",
    "\n",
    "question = \"what do I need to do to be successful at module 1?\"\n",
    "\n",
    "search_queries = []\n",
    "search_results = []\n",
    "previous_actions = []\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "while True:\n",
    "    print(f'ITERATION #{iteration}...')\n",
    "\n",
    "    context = build_context(search_results)\n",
    "    prompt = prompt_template.format(\n",
    "        question=question,\n",
    "        context=context,\n",
    "        search_queries=\"\\n\".join(search_queries),\n",
    "        previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "        max_iterations=3,\n",
    "        iteration_number=iteration\n",
    "    )\n",
    "\n",
    "    print(prompt)\n",
    "\n",
    "    answer_json = llm(prompt)\n",
    "    answer = json.loads(answer_json)\n",
    "    print(json.dumps(answer, indent=2))\n",
    "\n",
    "    previous_actions.append(answer)\n",
    "\n",
    "    action = answer['action']\n",
    "    if action != 'SEARCH':\n",
    "        break\n",
    "\n",
    "    keywords = answer['keywords']\n",
    "    search_queries = list(set(search_queries) | set(keywords))\n",
    "    \n",
    "    for k in keywords:\n",
    "        res = search(k)\n",
    "        search_results.extend(res)\n",
    "\n",
    "    search_results = dedup(search_results)\n",
    "    \n",
    "    iteration = iteration + 1\n",
    "    if iteration >= 4:\n",
    "        break\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b370b760-00b6-4a9f-a871-6b2534e796a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be successful in Module 1, which focuses on Docker and Terraform, here are some general tips:\n",
      "\n",
      "1. **Familiarize Yourself with the Basics**: Ensure you have a good understanding of the basic concepts of Docker and Terraform, including how to create, manage, and deploy containers using Docker, as well as infrastructure as code with Terraform.\n",
      "\n",
      "2. **Hands-On Practice**: Engage with the hands-on labs and exercises provided in the module. Practical application of concepts is crucial in understanding how these tools work in real-world scenarios.\n",
      "\n",
      "3. **Utilize Community Resources**: Leverage forums, YouTube tutorials, and documentation. The Docker and Terraform communities are vast, and you can find plenty of resources that will enhance your understanding.\n",
      "\n",
      "4. **Ask for Help**: Don't hesitate to reach out to peers or instructors if you have questions or encounter difficulties. Collaboration can enhance your learning experience.\n",
      "\n",
      "5. **Stay Organized**: Keep your notes, configuration files, and commands organized for easy reference while working through the module.\n",
      "\n",
      "6. **Review and Reinforce**: Regularly review what you've learned to reinforce the concepts. Building small projects or practice environments using Docker and Terraform can help solidify your knowledge.\n",
      "\n",
      "By focusing on these strategies, you can position yourself for success in Module 1.\n"
     ]
    }
   ],
   "source": [
    "print(answer['answer']) # for better look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62c2b829-d498-4755-bfda-321fbeffc9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b7da6d-c060-41ac-ac61-f53c6bcccef9",
   "metadata": {},
   "source": [
    "## STEP 7 - Function calling (\"tool use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a38727b-9713-453f-a5da-5cd071fef0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search tool\n",
    "\n",
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a953f43-55fc-4aa3-9ea4-747b9c7e2325",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'max_iterations'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m answer = \u001b[43mrag\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHow to run Kafka in Docker\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(answer)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mrag\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrag\u001b[39m(query):\n\u001b[32m      4\u001b[39m     search_results = search(query)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     prompt = \u001b[43mbuild_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     answer = llm(prompt)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m answer\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mbuild_prompt\u001b[39m\u001b[34m(query, search_results)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m search_results:\n\u001b[32m     20\u001b[39m     context = context + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc[\u001b[33m'\u001b[39m\u001b[33msection\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mquestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc[\u001b[33m'\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33manswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m prompt = \u001b[43mprompt_template\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m.strip()\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m prompt\n",
      "\u001b[31mKeyError\u001b[39m: 'max_iterations'"
     ]
    }
   ],
   "source": [
    "answer = rag(\"How to run Kafka in Docker\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4868ba76-c685-4003-bfa5-6ac3207940d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
